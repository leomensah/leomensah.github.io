{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CLASSIFICATION MODEL.ipynb",
      "provenance": [],
      "machine_shape": "hm",
      "mount_file_id": "1O1U08tcyv6Rm_WqQS_bHSOS5y_TEjCpt",
      "authorship_tag": "ABX9TyOJpnzEB6z6aDvf2l+5fy9Y",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "8510774b14a04271a3d9e3de2b32621b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8d7b4622d4574f168acfd897247d2b81",
              "IPY_MODEL_64ae4e2cbfcb453989d0d654486981da",
              "IPY_MODEL_c82312afbe454f4eb4f9ef99529b6837"
            ],
            "layout": "IPY_MODEL_6ce29191407a487a92dfc9b7f3760a53"
          }
        },
        "8d7b4622d4574f168acfd897247d2b81": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2c347dd9b89f4d2fbae149c2f86e476a",
            "placeholder": "​",
            "style": "IPY_MODEL_1d0d201e16824bd38f71fb01545ea097",
            "value": "100%"
          }
        },
        "64ae4e2cbfcb453989d0d654486981da": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7983daaf4ff44473be2c0ab6c4e6962f",
            "max": 21388428,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f21a4341fc924eb69603c26582e115fc",
            "value": 21388428
          }
        },
        "c82312afbe454f4eb4f9ef99529b6837": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_35f0354d06cc4149b6776c0597857178",
            "placeholder": "​",
            "style": "IPY_MODEL_97faa256ee22473dbd2860075c7c83f1",
            "value": " 20.4M/20.4M [00:00&lt;00:00, 116MB/s]"
          }
        },
        "6ce29191407a487a92dfc9b7f3760a53": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2c347dd9b89f4d2fbae149c2f86e476a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1d0d201e16824bd38f71fb01545ea097": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7983daaf4ff44473be2c0ab6c4e6962f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f21a4341fc924eb69603c26582e115fc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "35f0354d06cc4149b6776c0597857178": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "97faa256ee22473dbd2860075c7c83f1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/leomensah/leomensah.github.io/blob/main/CLASSIFICATION_MODEL.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **PREPARE DATASET FOR CLASSIFICATION MODEL**"
      ],
      "metadata": {
        "id": "_zJljGj324qs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "***EFFICIENT NETWORK MODEL --> FROM GOOGLE DEVELOPERS***\n",
        "1. Depth Scaling\n",
        "\n",
        "> RESNET helps in scaling the depth of the model by using a technique\n",
        "called skip connections.\n",
        "\n",
        "2. Width Scaling\n",
        "\n",
        "> Width scaling is changing the number of feature map, thus the number of feature maps\n",
        "\n",
        "3. Resolution Scaling\n",
        "\n",
        "> Resolution scaling is increasing the number of pixels.\n",
        "\n",
        "In order to pursue better accuracy, it is critical to balance all dimensions of network width, depth, and resolution during scaling.\n",
        "\n",
        "## **Compound scaling**\n"
      ],
      "metadata": {
        "id": "l8kIBmyWWhAZ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0tk4Zcksn6Xd"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns \n",
        "from scipy import ndimage as ndi\n",
        "from scipy import signal\n",
        "import pickle\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.feature_extraction import image"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_sample_image\n",
        "from sklearn.feature_extraction import image\n",
        "one_image = load_sample_image(\"china.jpg\")\n",
        "print('Image shape: {}'.format(one_image.shape))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "re5liYuBxEqH",
        "outputId": "f31ca3eb-9013-41f9-af8f-164a98f11cab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image shape: (427, 640, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_path_label(meta, is_clean=False):\n",
        "    \"\"\"This returns the path of image and mask and label list \"\"\"\n",
        "    image_path = list(meta['original_image'])\n",
        "    mask_path = list(meta['mask_image'])\n",
        "    if is_clean:\n",
        "        label = [0 for x in range(len(image_path))]\n",
        "    else:\n",
        "        label = list(meta['is_cancer'].apply(lambda x: 1 if x=='True' else 0))\n",
        "    return image_path,mask_path,label"
      ],
      "metadata": {
        "id": "tGq1HOVksOxL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def crop_clean_patch(clean_image,dim=224):\n",
        "    \"\"\"Crop random patch size of dim from clean dataset\"\"\"\n",
        "    clean_image = clean_image[100:400,100:400]\n",
        "    for i in range(100):  \n",
        "        patch = image.extract_patches_2d(clean_image,(dim,dim), max_patches=1)\n",
        "        patch = np.squeeze(patch)\n",
        "        if np.sum(patch)> 2000:\n",
        "            return patch\n",
        "    return patch"
      ],
      "metadata": {
        "id": "jihYaY9msYlY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def crop_nodule(coord,image,dim=112):\n",
        "  x_coord = int(coord[1])+ dim\n",
        "  y_coord = int(coord[0])+ dim\n",
        "  image_pad = np.pad(image, ((dim,dim),(dim,dim)), 'constant', constant_values=0)\n",
        "  return image_pad[y_coord-dim:y_coord+dim,x_coord-dim:x_coord+dim]"
      ],
      "metadata": {
        "id": "UntUbWwisehA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def gradient_transform(patch):\n",
        "  xder = np.array([[-1,0,1],[-2,0,2],[-1,0,1]])\n",
        "  yder = np.array([[1,2,1],[0,0,0],[-1,-2,-1]])\n",
        "  arrx = signal.convolve2d(patch,xder,mode='same')\n",
        "  arry = signal.convolve2d(patch,yder,mode='same')\n",
        "  return np.hypot(arrx,arry)"
      ],
      "metadata": {
        "id": "ufd7_fKwsrr4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def laplacian_transform(patch):\n",
        "    xder = np.array([[-1,0,1],[-2,0,2],[-1,0,1]])\n",
        "    yder = np.array([[1,2,1],[0,0,0],[-1,-2,-1]])\n",
        "    arrx = signal.convolve2d(patch,xder,mode='same')\n",
        "    arry = signal.convolve2d(patch,yder,mode='same')\n",
        "    arrx = signal.convolve2d(arrx,yder,mode='same')\n",
        "    arry = signal.convolve2d(arry,xder,mode='same')\n",
        "    return np.hypot(arrx,arry)"
      ],
      "metadata": {
        "id": "1mozLQils4Hx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_3channel(coord,image):\n",
        "    patch = crop_nodule(coord,image,dim=112)\n",
        "    grad_patch = gradient_transform(patch)\n",
        "    lap_patch = laplacian_transform(patch)\n",
        "    output = np.stack([patch,grad_patch,lap_patch],axis=2)\n",
        "    return output"
      ],
      "metadata": {
        "id": "crWgmq0js7-4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_3channel_clean(image):\n",
        "  patch = crop_clean_patch(image)\n",
        "  grad_patch = gradient_transform(patch)\n",
        "  lap_patch = laplacian_transform(patch)\n",
        "  output = np.stack([patch,grad_patch,lap_patch],axis=2)\n",
        "  return output"
      ],
      "metadata": {
        "id": "UI6FSLj2tBWX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "IMAGE_DIR = '/content/drive/MyDrive/data/Nodule_data/image/'\n",
        "MASK_DIR = '/content/drive/MyDrive/data/Nodule_data/mask/'\n",
        "\n",
        "# Directory to load data without any nodules, Thus, a clean lung image\n",
        "CLEAN_DIR_IMG ='/content/drive/MyDrive/Clean/image/'\n",
        "\n",
        "# Directory to save data\n",
        "train_output_rgb_dir = '/content/drive/MyDrive/data/Efficient_net/train/'\n",
        "val_output_rgb_dir = '/content/drive/MyDrive/data/Efficient_net/val/'\n",
        "test_output_rgb_dir = '/content/drive/MyDrive/data/Efficient_net/test/'\n",
        "data_label ='/content/drive/MyDrive/data/Efficient_net/label/'\n",
        "\n",
        "# Directory to save clean data\n",
        "clean_train_output_rgb_dir = '/content/drive/MyDrive/data/Efficient_net/clean_train/'\n",
        "clean_val_output_rgb_dir = '/content/drive/MyDrive/data/Efficient_net/clean_val/'\n",
        "clean_test_output_rgb_dir = '/content/drive/MyDrive/data/Efficient_net/clean_test/'\n",
        "\n",
        "#Meta Information\n",
        "meta = pd.read_csv('/content/drive/MyDrive/data/Meta_Beta/meta.csv')\n",
        "\n",
        "#Clean Meta Information\n",
        "clean_meta = pd.read_csv('/content/drive/MyDrive/data/Meta_Beta/clean_meta.csv')\n",
        "\n",
        "# Get train/test label from meta.csv\n",
        "meta['original_image']= meta['original_image'].apply(lambda x:IMAGE_DIR + x +'.npy')\n",
        "meta['mask_image'] = meta['mask_image'].apply(lambda x:MASK_DIR + x +'.npy')\n",
        "\n",
        "# Get train/test label from meta.csv\n",
        "clean_meta['original_image']= clean_meta['original_image'].apply(lambda x:CLEAN_DIR_IMG + x +'.npy')\n",
        "\n",
        "# Get images that were used to train Segmentation model and that is also not labeled as Ambiguous\n",
        "train_meta = meta[(meta['data_split']=='Train') & (meta['is_cancer']!='Ambiguous')]\n",
        "val_meta = meta[(meta['data_split']=='Validation') & (meta['is_cancer']!='Ambiguous')]\n",
        "test_meta = meta[(meta['data_split']=='Test') & (meta['is_cancer']!='Ambiguous')]\n",
        "\n",
        "# Get clean images that were used to train Segmentation model and that is also not labeled as Ambiguous\n",
        "clean_train_meta = clean_meta[(clean_meta['data_split']=='Train')]\n",
        "clean_val_meta = clean_meta[(clean_meta['data_split']=='Validation')]\n",
        "clean_test_meta = clean_meta[(clean_meta['data_split']=='Test')]\n",
        "\n",
        "train_image_paths,train_mask_paths, train_label  = get_path_label(train_meta)\n",
        "val_image_paths, val_mask_paths, val_label = get_path_label(val_meta)\n",
        "test_image_paths, test_mask_paths, test_label = get_path_label(test_meta)\n",
        "\n",
        "clean_train_image_paths,_ ,clean_train_label  = get_path_label(clean_train_meta,True)\n",
        "clean_val_image_paths,_ ,clean_val_label  = get_path_label(clean_val_meta,True)\n",
        "clean_test_image_paths,_ ,clean_test_label  = get_path_label(clean_test_meta,True)\n",
        "\n",
        "print(\"*\"*50)\n",
        "print(\"The length of image are train: {} test: {}\".format(len(train_image_paths),len(test_image_paths)))\n",
        "\n",
        " #load train and save as 3 channel file\n",
        "for train_img,train_mask in zip(train_image_paths,train_mask_paths):\n",
        "  naming = train_img[-23:]\n",
        "  mask = np.load(train_mask)\n",
        "  image = np.load(train_img)\n",
        "  rgb= create_3channel(ndi.center_of_mass(mask),image)\n",
        "  print(\"Saved {}\".format(naming))\n",
        "  np.save(train_output_rgb_dir+naming,rgb)\n",
        "\n",
        "#load validation and save as 3 channel file\n",
        "for val_img,val_mask in zip(val_image_paths,val_mask_paths):\n",
        "  naming = val_img[-23:]\n",
        "  mask = np.load(val_mask)\n",
        "  image = np.load(val_img)\n",
        "  rgb= create_3channel(ndi.center_of_mass(mask),image)\n",
        "  print(\"Saved {}\".format(naming))\n",
        "  np.save(val_output_rgb_dir+naming,rgb)\n",
        "\n",
        "for test_img,test_mask in zip(test_image_paths,test_mask_paths):\n",
        "  naming = test_img[-23:]\n",
        "  mask = np.load(test_mask)\n",
        "  image = np.load(test_img)\n",
        "  rgb= create_3channel(ndi.center_of_mass(mask),image)\n",
        "  print(\"Saved {}\".format(naming))\n",
        "  np.save(test_output_rgb_dir+naming,rgb)"
      ],
      "metadata": {
        "id": "2aubrjSk3P1A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_sample_image\n",
        "from sklearn.feature_extraction import image\n",
        "one_image = load_sample_image(\"china.jpg\")\n",
        "print(type(one_image))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mCEKzXFJz1qU",
        "outputId": "4179218c-a874-4b32-9f48-9b5440158704"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'numpy.ndarray'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for train_img in clean_train_image_paths[:800]:\n",
        "    naming = train_img[-23:]\n",
        "    new_image = np.load(train_img)\n",
        "    clean_image = new_image[100:400,100:400]\n",
        "    print(type(clean_image))\n",
        "    print(clean_image.shape)\n",
        "    patches = image.extract_patches_2d(clean_image, (224, 224))\n",
        "    # patch = image.extract_patches_2d(clean_image,(224,224),1)\n",
        "    # for i in range(100):  \n",
        "        #patch = image.extract_patches_2d(clean_image,(224,224),1)\n",
        "        # patch = np.squeeze(patch)\n",
        "        # if np.sum(patch)> 2000:\n",
        "        #     return patch\n",
        "    print(patches)\n",
        "    print(type(clean_image))\n",
        "    break\n",
        "    rgb = create_3channel_clean(image)"
      ],
      "metadata": {
        "id": "Xdhqlwz6zQdx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Converting the clean dataset to rgb and training\n",
        "# and saving the output\n",
        "for train_img in clean_train_image_paths[:800]:\n",
        "    naming = train_img[-23:]\n",
        "    new_image = np.load(train_img)\n",
        "    rgb = create_3channel_clean(new_image)\n",
        "    print(\"Saved {}\".format(naming))\n",
        "    np.save(clean_train_output_rgb_dir+naming,rgb)\n",
        "\n",
        "for val_img in clean_val_image_paths[:400]:\n",
        "    naming = val_img[-23:]\n",
        "    new_image = np.load(val_img)\n",
        "    rgb = create_3channel_clean(new_image)\n",
        "    print(\"Saved {}\".format(naming))\n",
        "    #np.save(clean_val_output_rgb_dir+naming,rgb)\n",
        "\n",
        "for test_img in clean_test_image_paths[:400]:\n",
        "    naming = test_img[-23:]\n",
        "    new_image = np.load(test_img)\n",
        "    rgb = create_3channel_clean(new_image)\n",
        "    print(\"Saved {}\".format(naming))\n",
        "    np.save(clean_test_output_rgb_dir+naming,rgb)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "31z7aWrBYwWG",
        "outputId": "cbfe2fd5-3767-4104-c37e-d72c45e3e41a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved 0028_CN001_slice000.npy\n",
            "Saved 0028_CN001_slice001.npy\n",
            "Saved 0028_CN001_slice002.npy\n",
            "Saved 0028_CN001_slice003.npy\n",
            "Saved 0028_CN001_slice004.npy\n",
            "Saved 0028_CN001_slice005.npy\n",
            "Saved 0028_CN001_slice006.npy\n",
            "Saved 0028_CN001_slice007.npy\n",
            "Saved 0028_CN001_slice008.npy\n",
            "Saved 0028_CN001_slice009.npy\n",
            "Saved 0028_CN001_slice010.npy\n",
            "Saved 0028_CN001_slice011.npy\n",
            "Saved 0028_CN001_slice012.npy\n",
            "Saved 0028_CN001_slice013.npy\n",
            "Saved 0028_CN001_slice014.npy\n",
            "Saved 0028_CN001_slice015.npy\n",
            "Saved 0028_CN001_slice016.npy\n",
            "Saved 0028_CN001_slice017.npy\n",
            "Saved 0028_CN001_slice018.npy\n",
            "Saved 0028_CN001_slice019.npy\n",
            "Saved 0028_CN001_slice020.npy\n",
            "Saved 0028_CN001_slice021.npy\n",
            "Saved 0028_CN001_slice022.npy\n",
            "Saved 0028_CN001_slice023.npy\n",
            "Saved 0028_CN001_slice024.npy\n",
            "Saved 0028_CN001_slice025.npy\n",
            "Saved 0028_CN001_slice026.npy\n",
            "Saved 0028_CN001_slice027.npy\n",
            "Saved 0028_CN001_slice028.npy\n",
            "Saved 0028_CN001_slice029.npy\n",
            "Saved 0028_CN001_slice030.npy\n",
            "Saved 0028_CN001_slice031.npy\n",
            "Saved 0028_CN001_slice032.npy\n",
            "Saved 0028_CN001_slice033.npy\n",
            "Saved 0028_CN001_slice034.npy\n",
            "Saved 0028_CN001_slice035.npy\n",
            "Saved 0028_CN001_slice036.npy\n",
            "Saved 0028_CN001_slice037.npy\n",
            "Saved 0028_CN001_slice038.npy\n",
            "Saved 0028_CN001_slice039.npy\n",
            "Saved 0028_CN001_slice040.npy\n",
            "Saved 0028_CN001_slice041.npy\n",
            "Saved 0028_CN001_slice042.npy\n",
            "Saved 0028_CN001_slice043.npy\n",
            "Saved 0028_CN001_slice044.npy\n",
            "Saved 0028_CN001_slice045.npy\n",
            "Saved 0028_CN001_slice046.npy\n",
            "Saved 0028_CN001_slice047.npy\n",
            "Saved 0028_CN001_slice048.npy\n",
            "Saved 0028_CN001_slice049.npy\n",
            "Saved 0028_CN001_slice050.npy\n",
            "Saved 0032_CN001_slice000.npy\n",
            "Saved 0032_CN001_slice001.npy\n",
            "Saved 0032_CN001_slice002.npy\n",
            "Saved 0032_CN001_slice003.npy\n",
            "Saved 0032_CN001_slice004.npy\n",
            "Saved 0032_CN001_slice005.npy\n",
            "Saved 0032_CN001_slice006.npy\n",
            "Saved 0032_CN001_slice007.npy\n",
            "Saved 0032_CN001_slice008.npy\n",
            "Saved 0032_CN001_slice009.npy\n",
            "Saved 0032_CN001_slice010.npy\n",
            "Saved 0032_CN001_slice011.npy\n",
            "Saved 0032_CN001_slice012.npy\n",
            "Saved 0032_CN001_slice013.npy\n",
            "Saved 0032_CN001_slice014.npy\n",
            "Saved 0032_CN001_slice015.npy\n",
            "Saved 0032_CN001_slice016.npy\n",
            "Saved 0032_CN001_slice017.npy\n",
            "Saved 0032_CN001_slice018.npy\n",
            "Saved 0032_CN001_slice019.npy\n",
            "Saved 0032_CN001_slice020.npy\n",
            "Saved 0032_CN001_slice021.npy\n",
            "Saved 0032_CN001_slice022.npy\n",
            "Saved 0032_CN001_slice023.npy\n",
            "Saved 0032_CN001_slice024.npy\n",
            "Saved 0032_CN001_slice025.npy\n",
            "Saved 0032_CN001_slice026.npy\n",
            "Saved 0032_CN001_slice027.npy\n",
            "Saved 0032_CN001_slice028.npy\n",
            "Saved 0032_CN001_slice029.npy\n",
            "Saved 0032_CN001_slice030.npy\n",
            "Saved 0032_CN001_slice031.npy\n",
            "Saved 0032_CN001_slice032.npy\n",
            "Saved 0032_CN001_slice033.npy\n",
            "Saved 0032_CN001_slice034.npy\n",
            "Saved 0032_CN001_slice035.npy\n",
            "Saved 0032_CN001_slice036.npy\n",
            "Saved 0032_CN001_slice037.npy\n",
            "Saved 0032_CN001_slice038.npy\n",
            "Saved 0032_CN001_slice039.npy\n",
            "Saved 0032_CN001_slice040.npy\n",
            "Saved 0032_CN001_slice041.npy\n",
            "Saved 0032_CN001_slice042.npy\n",
            "Saved 0032_CN001_slice043.npy\n",
            "Saved 0032_CN001_slice044.npy\n",
            "Saved 0032_CN001_slice045.npy\n",
            "Saved 0032_CN001_slice046.npy\n",
            "Saved 0032_CN001_slice047.npy\n",
            "Saved 0032_CN001_slice048.npy\n",
            "Saved 0032_CN001_slice049.npy\n",
            "Saved 0032_CN001_slice050.npy\n",
            "Saved 0071_CN001_slice000.npy\n",
            "Saved 0071_CN001_slice001.npy\n",
            "Saved 0071_CN001_slice002.npy\n",
            "Saved 0071_CN001_slice003.npy\n",
            "Saved 0071_CN001_slice004.npy\n",
            "Saved 0071_CN001_slice005.npy\n",
            "Saved 0071_CN001_slice006.npy\n",
            "Saved 0071_CN001_slice007.npy\n",
            "Saved 0071_CN001_slice008.npy\n",
            "Saved 0071_CN001_slice009.npy\n",
            "Saved 0071_CN001_slice010.npy\n",
            "Saved 0071_CN001_slice011.npy\n",
            "Saved 0071_CN001_slice012.npy\n",
            "Saved 0071_CN001_slice013.npy\n",
            "Saved 0071_CN001_slice014.npy\n",
            "Saved 0071_CN001_slice015.npy\n",
            "Saved 0071_CN001_slice016.npy\n",
            "Saved 0071_CN001_slice017.npy\n",
            "Saved 0071_CN001_slice018.npy\n",
            "Saved 0071_CN001_slice019.npy\n",
            "Saved 0071_CN001_slice020.npy\n",
            "Saved 0071_CN001_slice021.npy\n",
            "Saved 0071_CN001_slice022.npy\n",
            "Saved 0071_CN001_slice023.npy\n",
            "Saved 0071_CN001_slice024.npy\n",
            "Saved 0071_CN001_slice025.npy\n",
            "Saved 0071_CN001_slice026.npy\n",
            "Saved 0071_CN001_slice027.npy\n",
            "Saved 0071_CN001_slice028.npy\n",
            "Saved 0071_CN001_slice029.npy\n",
            "Saved 0071_CN001_slice030.npy\n",
            "Saved 0071_CN001_slice031.npy\n",
            "Saved 0071_CN001_slice032.npy\n",
            "Saved 0071_CN001_slice033.npy\n",
            "Saved 0071_CN001_slice034.npy\n",
            "Saved 0071_CN001_slice035.npy\n",
            "Saved 0071_CN001_slice036.npy\n",
            "Saved 0071_CN001_slice037.npy\n",
            "Saved 0071_CN001_slice038.npy\n",
            "Saved 0071_CN001_slice039.npy\n",
            "Saved 0071_CN001_slice040.npy\n",
            "Saved 0071_CN001_slice041.npy\n",
            "Saved 0071_CN001_slice042.npy\n",
            "Saved 0071_CN001_slice043.npy\n",
            "Saved 0071_CN001_slice044.npy\n",
            "Saved 0071_CN001_slice045.npy\n",
            "Saved 0071_CN001_slice046.npy\n",
            "Saved 0071_CN001_slice047.npy\n",
            "Saved 0071_CN001_slice048.npy\n",
            "Saved 0071_CN001_slice049.npy\n",
            "Saved 0071_CN001_slice050.npy\n",
            "Saved 0100_CN001_slice000.npy\n",
            "Saved 0100_CN001_slice001.npy\n",
            "Saved 0100_CN001_slice002.npy\n",
            "Saved 0100_CN001_slice003.npy\n",
            "Saved 0100_CN001_slice004.npy\n",
            "Saved 0100_CN001_slice005.npy\n",
            "Saved 0100_CN001_slice006.npy\n",
            "Saved 0100_CN001_slice007.npy\n",
            "Saved 0100_CN001_slice008.npy\n",
            "Saved 0100_CN001_slice009.npy\n",
            "Saved 0100_CN001_slice010.npy\n",
            "Saved 0100_CN001_slice011.npy\n",
            "Saved 0100_CN001_slice012.npy\n",
            "Saved 0100_CN001_slice013.npy\n",
            "Saved 0100_CN001_slice014.npy\n",
            "Saved 0100_CN001_slice015.npy\n",
            "Saved 0100_CN001_slice016.npy\n",
            "Saved 0100_CN001_slice017.npy\n",
            "Saved 0100_CN001_slice018.npy\n",
            "Saved 0100_CN001_slice019.npy\n",
            "Saved 0100_CN001_slice020.npy\n",
            "Saved 0100_CN001_slice021.npy\n",
            "Saved 0100_CN001_slice022.npy\n",
            "Saved 0100_CN001_slice023.npy\n",
            "Saved 0100_CN001_slice024.npy\n",
            "Saved 0100_CN001_slice025.npy\n",
            "Saved 0100_CN001_slice026.npy\n",
            "Saved 0100_CN001_slice027.npy\n",
            "Saved 0100_CN001_slice028.npy\n",
            "Saved 0100_CN001_slice029.npy\n",
            "Saved 0100_CN001_slice030.npy\n",
            "Saved 0100_CN001_slice031.npy\n",
            "Saved 0100_CN001_slice032.npy\n",
            "Saved 0100_CN001_slice033.npy\n",
            "Saved 0100_CN001_slice034.npy\n",
            "Saved 0100_CN001_slice035.npy\n",
            "Saved 0100_CN001_slice036.npy\n",
            "Saved 0100_CN001_slice037.npy\n",
            "Saved 0100_CN001_slice038.npy\n",
            "Saved 0100_CN001_slice039.npy\n",
            "Saved 0100_CN001_slice040.npy\n",
            "Saved 0100_CN001_slice041.npy\n",
            "Saved 0100_CN001_slice042.npy\n",
            "Saved 0100_CN001_slice043.npy\n",
            "Saved 0100_CN001_slice044.npy\n",
            "Saved 0100_CN001_slice045.npy\n",
            "Saved 0100_CN001_slice046.npy\n",
            "Saved 0100_CN001_slice047.npy\n",
            "Saved 0100_CN001_slice048.npy\n",
            "Saved 0100_CN001_slice049.npy\n",
            "Saved 0100_CN001_slice050.npy\n",
            "Saved 0143_CN001_slice000.npy\n",
            "Saved 0143_CN001_slice001.npy\n",
            "Saved 0143_CN001_slice002.npy\n",
            "Saved 0143_CN001_slice003.npy\n",
            "Saved 0143_CN001_slice004.npy\n",
            "Saved 0143_CN001_slice005.npy\n",
            "Saved 0143_CN001_slice006.npy\n",
            "Saved 0143_CN001_slice007.npy\n",
            "Saved 0143_CN001_slice008.npy\n",
            "Saved 0143_CN001_slice009.npy\n",
            "Saved 0143_CN001_slice010.npy\n",
            "Saved 0143_CN001_slice011.npy\n",
            "Saved 0143_CN001_slice012.npy\n",
            "Saved 0143_CN001_slice013.npy\n",
            "Saved 0143_CN001_slice014.npy\n",
            "Saved 0143_CN001_slice015.npy\n",
            "Saved 0143_CN001_slice016.npy\n",
            "Saved 0143_CN001_slice017.npy\n",
            "Saved 0143_CN001_slice018.npy\n",
            "Saved 0143_CN001_slice019.npy\n",
            "Saved 0143_CN001_slice020.npy\n",
            "Saved 0143_CN001_slice021.npy\n",
            "Saved 0143_CN001_slice022.npy\n",
            "Saved 0143_CN001_slice023.npy\n",
            "Saved 0143_CN001_slice024.npy\n",
            "Saved 0143_CN001_slice025.npy\n",
            "Saved 0143_CN001_slice026.npy\n",
            "Saved 0143_CN001_slice027.npy\n",
            "Saved 0143_CN001_slice028.npy\n",
            "Saved 0143_CN001_slice029.npy\n",
            "Saved 0143_CN001_slice030.npy\n",
            "Saved 0143_CN001_slice031.npy\n",
            "Saved 0143_CN001_slice032.npy\n",
            "Saved 0143_CN001_slice033.npy\n",
            "Saved 0143_CN001_slice034.npy\n",
            "Saved 0143_CN001_slice035.npy\n",
            "Saved 0143_CN001_slice036.npy\n",
            "Saved 0143_CN001_slice037.npy\n",
            "Saved 0143_CN001_slice038.npy\n",
            "Saved 0143_CN001_slice039.npy\n",
            "Saved 0143_CN001_slice040.npy\n",
            "Saved 0143_CN001_slice041.npy\n",
            "Saved 0143_CN001_slice042.npy\n",
            "Saved 0143_CN001_slice043.npy\n",
            "Saved 0143_CN001_slice044.npy\n",
            "Saved 0143_CN001_slice045.npy\n",
            "Saved 0143_CN001_slice046.npy\n",
            "Saved 0143_CN001_slice047.npy\n",
            "Saved 0143_CN001_slice048.npy\n",
            "Saved 0143_CN001_slice049.npy\n",
            "Saved 0143_CN001_slice050.npy\n",
            "Saved 0174_CN001_slice000.npy\n",
            "Saved 0174_CN001_slice001.npy\n",
            "Saved 0174_CN001_slice002.npy\n",
            "Saved 0174_CN001_slice003.npy\n",
            "Saved 0174_CN001_slice004.npy\n",
            "Saved 0174_CN001_slice005.npy\n",
            "Saved 0174_CN001_slice006.npy\n",
            "Saved 0174_CN001_slice007.npy\n",
            "Saved 0174_CN001_slice008.npy\n",
            "Saved 0174_CN001_slice009.npy\n",
            "Saved 0174_CN001_slice010.npy\n",
            "Saved 0174_CN001_slice011.npy\n",
            "Saved 0174_CN001_slice012.npy\n",
            "Saved 0174_CN001_slice013.npy\n",
            "Saved 0174_CN001_slice014.npy\n",
            "Saved 0174_CN001_slice015.npy\n",
            "Saved 0174_CN001_slice016.npy\n",
            "Saved 0174_CN001_slice017.npy\n",
            "Saved 0174_CN001_slice018.npy\n",
            "Saved 0174_CN001_slice019.npy\n",
            "Saved 0174_CN001_slice020.npy\n",
            "Saved 0174_CN001_slice021.npy\n",
            "Saved 0174_CN001_slice022.npy\n",
            "Saved 0174_CN001_slice023.npy\n",
            "Saved 0174_CN001_slice024.npy\n",
            "Saved 0174_CN001_slice025.npy\n",
            "Saved 0174_CN001_slice026.npy\n",
            "Saved 0174_CN001_slice027.npy\n",
            "Saved 0174_CN001_slice028.npy\n",
            "Saved 0174_CN001_slice029.npy\n",
            "Saved 0174_CN001_slice030.npy\n",
            "Saved 0174_CN001_slice031.npy\n",
            "Saved 0174_CN001_slice032.npy\n",
            "Saved 0174_CN001_slice033.npy\n",
            "Saved 0174_CN001_slice034.npy\n",
            "Saved 0174_CN001_slice035.npy\n",
            "Saved 0174_CN001_slice036.npy\n",
            "Saved 0174_CN001_slice037.npy\n",
            "Saved 0174_CN001_slice038.npy\n",
            "Saved 0174_CN001_slice039.npy\n",
            "Saved 0174_CN001_slice040.npy\n",
            "Saved 0174_CN001_slice041.npy\n",
            "Saved 0174_CN001_slice042.npy\n",
            "Saved 0174_CN001_slice043.npy\n",
            "Saved 0174_CN001_slice044.npy\n",
            "Saved 0174_CN001_slice045.npy\n",
            "Saved 0174_CN001_slice046.npy\n",
            "Saved 0174_CN001_slice047.npy\n",
            "Saved 0174_CN001_slice048.npy\n",
            "Saved 0174_CN001_slice049.npy\n",
            "Saved 0174_CN001_slice050.npy\n",
            "Saved 0189_CN001_slice000.npy\n",
            "Saved 0189_CN001_slice001.npy\n",
            "Saved 0189_CN001_slice002.npy\n",
            "Saved 0189_CN001_slice003.npy\n",
            "Saved 0189_CN001_slice004.npy\n",
            "Saved 0189_CN001_slice005.npy\n",
            "Saved 0189_CN001_slice006.npy\n",
            "Saved 0189_CN001_slice007.npy\n",
            "Saved 0189_CN001_slice008.npy\n",
            "Saved 0189_CN001_slice009.npy\n",
            "Saved 0189_CN001_slice010.npy\n",
            "Saved 0189_CN001_slice011.npy\n",
            "Saved 0189_CN001_slice012.npy\n",
            "Saved 0189_CN001_slice013.npy\n",
            "Saved 0189_CN001_slice014.npy\n",
            "Saved 0189_CN001_slice015.npy\n",
            "Saved 0189_CN001_slice016.npy\n",
            "Saved 0189_CN001_slice017.npy\n",
            "Saved 0189_CN001_slice018.npy\n",
            "Saved 0189_CN001_slice019.npy\n",
            "Saved 0189_CN001_slice020.npy\n",
            "Saved 0189_CN001_slice021.npy\n",
            "Saved 0189_CN001_slice022.npy\n",
            "Saved 0189_CN001_slice023.npy\n",
            "Saved 0189_CN001_slice024.npy\n",
            "Saved 0189_CN001_slice025.npy\n",
            "Saved 0189_CN001_slice026.npy\n",
            "Saved 0189_CN001_slice027.npy\n",
            "Saved 0189_CN001_slice028.npy\n",
            "Saved 0189_CN001_slice029.npy\n",
            "Saved 0189_CN001_slice030.npy\n",
            "Saved 0189_CN001_slice031.npy\n",
            "Saved 0189_CN001_slice032.npy\n",
            "Saved 0189_CN001_slice033.npy\n",
            "Saved 0189_CN001_slice034.npy\n",
            "Saved 0189_CN001_slice035.npy\n",
            "Saved 0189_CN001_slice036.npy\n",
            "Saved 0189_CN001_slice037.npy\n",
            "Saved 0189_CN001_slice038.npy\n",
            "Saved 0189_CN001_slice039.npy\n",
            "Saved 0189_CN001_slice040.npy\n",
            "Saved 0189_CN001_slice041.npy\n",
            "Saved 0189_CN001_slice042.npy\n",
            "Saved 0189_CN001_slice043.npy\n",
            "Saved 0189_CN001_slice044.npy\n",
            "Saved 0189_CN001_slice045.npy\n",
            "Saved 0189_CN001_slice046.npy\n",
            "Saved 0189_CN001_slice047.npy\n",
            "Saved 0189_CN001_slice048.npy\n",
            "Saved 0189_CN001_slice049.npy\n",
            "Saved 0189_CN001_slice050.npy\n",
            "Saved 0205_CN001_slice000.npy\n",
            "Saved 0205_CN001_slice001.npy\n",
            "Saved 0205_CN001_slice002.npy\n",
            "Saved 0205_CN001_slice003.npy\n",
            "Saved 0205_CN001_slice004.npy\n",
            "Saved 0205_CN001_slice005.npy\n",
            "Saved 0205_CN001_slice006.npy\n",
            "Saved 0205_CN001_slice007.npy\n",
            "Saved 0205_CN001_slice008.npy\n",
            "Saved 0205_CN001_slice009.npy\n",
            "Saved 0205_CN001_slice010.npy\n",
            "Saved 0205_CN001_slice011.npy\n",
            "Saved 0205_CN001_slice012.npy\n",
            "Saved 0205_CN001_slice013.npy\n",
            "Saved 0205_CN001_slice014.npy\n",
            "Saved 0205_CN001_slice015.npy\n",
            "Saved 0205_CN001_slice016.npy\n",
            "Saved 0205_CN001_slice017.npy\n",
            "Saved 0205_CN001_slice018.npy\n",
            "Saved 0205_CN001_slice019.npy\n",
            "Saved 0205_CN001_slice020.npy\n",
            "Saved 0205_CN001_slice021.npy\n",
            "Saved 0205_CN001_slice022.npy\n",
            "Saved 0205_CN001_slice023.npy\n",
            "Saved 0205_CN001_slice024.npy\n",
            "Saved 0205_CN001_slice025.npy\n",
            "Saved 0205_CN001_slice026.npy\n",
            "Saved 0205_CN001_slice027.npy\n",
            "Saved 0205_CN001_slice028.npy\n",
            "Saved 0205_CN001_slice029.npy\n",
            "Saved 0205_CN001_slice030.npy\n",
            "Saved 0205_CN001_slice031.npy\n",
            "Saved 0205_CN001_slice032.npy\n",
            "Saved 0205_CN001_slice033.npy\n",
            "Saved 0205_CN001_slice034.npy\n",
            "Saved 0205_CN001_slice035.npy\n",
            "Saved 0205_CN001_slice036.npy\n",
            "Saved 0205_CN001_slice037.npy\n",
            "Saved 0205_CN001_slice038.npy\n",
            "Saved 0205_CN001_slice039.npy\n",
            "Saved 0205_CN001_slice040.npy\n",
            "Saved 0205_CN001_slice041.npy\n",
            "Saved 0205_CN001_slice042.npy\n",
            "Saved 0205_CN001_slice043.npy\n",
            "Saved 0205_CN001_slice044.npy\n",
            "Saved 0205_CN001_slice045.npy\n",
            "Saved 0205_CN001_slice046.npy\n",
            "Saved 0205_CN001_slice047.npy\n",
            "Saved 0205_CN001_slice048.npy\n",
            "Saved 0205_CN001_slice049.npy\n",
            "Saved 0205_CN001_slice050.npy\n",
            "Saved 0218_CN001_slice000.npy\n",
            "Saved 0218_CN001_slice001.npy\n",
            "Saved 0218_CN001_slice002.npy\n",
            "Saved 0218_CN001_slice003.npy\n",
            "Saved 0218_CN001_slice004.npy\n",
            "Saved 0218_CN001_slice005.npy\n",
            "Saved 0218_CN001_slice006.npy\n",
            "Saved 0218_CN001_slice007.npy\n",
            "Saved 0218_CN001_slice008.npy\n",
            "Saved 0218_CN001_slice009.npy\n",
            "Saved 0218_CN001_slice010.npy\n",
            "Saved 0218_CN001_slice011.npy\n",
            "Saved 0218_CN001_slice012.npy\n",
            "Saved 0218_CN001_slice013.npy\n",
            "Saved 0218_CN001_slice014.npy\n",
            "Saved 0218_CN001_slice015.npy\n",
            "Saved 0218_CN001_slice016.npy\n",
            "Saved 0218_CN001_slice017.npy\n",
            "Saved 0218_CN001_slice018.npy\n",
            "Saved 0218_CN001_slice019.npy\n",
            "Saved 0218_CN001_slice020.npy\n",
            "Saved 0218_CN001_slice021.npy\n",
            "Saved 0218_CN001_slice022.npy\n",
            "Saved 0218_CN001_slice023.npy\n",
            "Saved 0218_CN001_slice024.npy\n",
            "Saved 0218_CN001_slice025.npy\n",
            "Saved 0218_CN001_slice026.npy\n",
            "Saved 0218_CN001_slice027.npy\n",
            "Saved 0218_CN001_slice028.npy\n",
            "Saved 0218_CN001_slice029.npy\n",
            "Saved 0218_CN001_slice030.npy\n",
            "Saved 0218_CN001_slice031.npy\n",
            "Saved 0218_CN001_slice032.npy\n",
            "Saved 0218_CN001_slice033.npy\n",
            "Saved 0218_CN001_slice034.npy\n",
            "Saved 0218_CN001_slice035.npy\n",
            "Saved 0218_CN001_slice036.npy\n",
            "Saved 0218_CN001_slice037.npy\n",
            "Saved 0218_CN001_slice038.npy\n",
            "Saved 0218_CN001_slice039.npy\n",
            "Saved 0218_CN001_slice040.npy\n",
            "Saved 0218_CN001_slice041.npy\n",
            "Saved 0218_CN001_slice042.npy\n",
            "Saved 0218_CN001_slice043.npy\n",
            "Saved 0218_CN001_slice044.npy\n",
            "Saved 0218_CN001_slice045.npy\n",
            "Saved 0218_CN001_slice046.npy\n",
            "Saved 0218_CN001_slice047.npy\n",
            "Saved 0218_CN001_slice048.npy\n",
            "Saved 0218_CN001_slice049.npy\n",
            "Saved 0218_CN001_slice050.npy\n",
            "Saved 0224_CN001_slice000.npy\n",
            "Saved 0224_CN001_slice001.npy\n",
            "Saved 0224_CN001_slice002.npy\n",
            "Saved 0224_CN001_slice003.npy\n",
            "Saved 0224_CN001_slice004.npy\n",
            "Saved 0224_CN001_slice005.npy\n",
            "Saved 0224_CN001_slice006.npy\n",
            "Saved 0224_CN001_slice007.npy\n",
            "Saved 0224_CN001_slice008.npy\n",
            "Saved 0224_CN001_slice009.npy\n",
            "Saved 0224_CN001_slice010.npy\n",
            "Saved 0224_CN001_slice011.npy\n",
            "Saved 0224_CN001_slice012.npy\n",
            "Saved 0224_CN001_slice013.npy\n",
            "Saved 0224_CN001_slice014.npy\n",
            "Saved 0224_CN001_slice015.npy\n",
            "Saved 0224_CN001_slice016.npy\n",
            "Saved 0224_CN001_slice017.npy\n",
            "Saved 0224_CN001_slice018.npy\n",
            "Saved 0224_CN001_slice019.npy\n",
            "Saved 0224_CN001_slice020.npy\n",
            "Saved 0224_CN001_slice021.npy\n",
            "Saved 0224_CN001_slice022.npy\n",
            "Saved 0224_CN001_slice023.npy\n",
            "Saved 0224_CN001_slice024.npy\n",
            "Saved 0224_CN001_slice025.npy\n",
            "Saved 0224_CN001_slice026.npy\n",
            "Saved 0224_CN001_slice027.npy\n",
            "Saved 0224_CN001_slice028.npy\n",
            "Saved 0224_CN001_slice029.npy\n",
            "Saved 0224_CN001_slice030.npy\n",
            "Saved 0224_CN001_slice031.npy\n",
            "Saved 0224_CN001_slice032.npy\n",
            "Saved 0224_CN001_slice033.npy\n",
            "Saved 0224_CN001_slice034.npy\n",
            "Saved 0224_CN001_slice035.npy\n",
            "Saved 0224_CN001_slice036.npy\n",
            "Saved 0224_CN001_slice037.npy\n",
            "Saved 0224_CN001_slice038.npy\n",
            "Saved 0224_CN001_slice039.npy\n",
            "Saved 0224_CN001_slice040.npy\n",
            "Saved 0224_CN001_slice041.npy\n",
            "Saved 0224_CN001_slice042.npy\n",
            "Saved 0224_CN001_slice043.npy\n",
            "Saved 0224_CN001_slice044.npy\n",
            "Saved 0224_CN001_slice045.npy\n",
            "Saved 0224_CN001_slice046.npy\n",
            "Saved 0224_CN001_slice047.npy\n",
            "Saved 0224_CN001_slice048.npy\n",
            "Saved 0224_CN001_slice049.npy\n",
            "Saved 0224_CN001_slice050.npy\n",
            "Saved 0225_CN001_slice000.npy\n",
            "Saved 0225_CN001_slice001.npy\n",
            "Saved 0225_CN001_slice002.npy\n",
            "Saved 0225_CN001_slice003.npy\n",
            "Saved 0225_CN001_slice004.npy\n",
            "Saved 0225_CN001_slice005.npy\n",
            "Saved 0225_CN001_slice006.npy\n",
            "Saved 0225_CN001_slice007.npy\n",
            "Saved 0225_CN001_slice008.npy\n",
            "Saved 0225_CN001_slice009.npy\n",
            "Saved 0225_CN001_slice010.npy\n",
            "Saved 0225_CN001_slice011.npy\n",
            "Saved 0225_CN001_slice012.npy\n",
            "Saved 0225_CN001_slice013.npy\n",
            "Saved 0225_CN001_slice014.npy\n",
            "Saved 0225_CN001_slice015.npy\n",
            "Saved 0225_CN001_slice016.npy\n",
            "Saved 0225_CN001_slice017.npy\n",
            "Saved 0225_CN001_slice018.npy\n",
            "Saved 0225_CN001_slice019.npy\n",
            "Saved 0225_CN001_slice020.npy\n",
            "Saved 0225_CN001_slice021.npy\n",
            "Saved 0225_CN001_slice022.npy\n",
            "Saved 0225_CN001_slice023.npy\n",
            "Saved 0225_CN001_slice024.npy\n",
            "Saved 0225_CN001_slice025.npy\n",
            "Saved 0225_CN001_slice026.npy\n",
            "Saved 0225_CN001_slice027.npy\n",
            "Saved 0225_CN001_slice028.npy\n",
            "Saved 0225_CN001_slice029.npy\n",
            "Saved 0225_CN001_slice030.npy\n",
            "Saved 0225_CN001_slice031.npy\n",
            "Saved 0225_CN001_slice032.npy\n",
            "Saved 0225_CN001_slice033.npy\n",
            "Saved 0225_CN001_slice034.npy\n",
            "Saved 0225_CN001_slice035.npy\n",
            "Saved 0225_CN001_slice036.npy\n",
            "Saved 0225_CN001_slice037.npy\n",
            "Saved 0225_CN001_slice038.npy\n",
            "Saved 0225_CN001_slice039.npy\n",
            "Saved 0225_CN001_slice040.npy\n",
            "Saved 0225_CN001_slice041.npy\n",
            "Saved 0225_CN001_slice042.npy\n",
            "Saved 0225_CN001_slice043.npy\n",
            "Saved 0225_CN001_slice044.npy\n",
            "Saved 0225_CN001_slice045.npy\n",
            "Saved 0225_CN001_slice046.npy\n",
            "Saved 0225_CN001_slice047.npy\n",
            "Saved 0225_CN001_slice048.npy\n",
            "Saved 0225_CN001_slice049.npy\n",
            "Saved 0225_CN001_slice050.npy\n",
            "Saved 0226_CN001_slice000.npy\n",
            "Saved 0226_CN001_slice001.npy\n",
            "Saved 0226_CN001_slice002.npy\n",
            "Saved 0226_CN001_slice003.npy\n",
            "Saved 0226_CN001_slice004.npy\n",
            "Saved 0226_CN001_slice005.npy\n",
            "Saved 0226_CN001_slice006.npy\n",
            "Saved 0226_CN001_slice007.npy\n",
            "Saved 0226_CN001_slice008.npy\n",
            "Saved 0226_CN001_slice009.npy\n",
            "Saved 0226_CN001_slice010.npy\n",
            "Saved 0226_CN001_slice011.npy\n",
            "Saved 0226_CN001_slice012.npy\n",
            "Saved 0226_CN001_slice013.npy\n",
            "Saved 0226_CN001_slice014.npy\n",
            "Saved 0226_CN001_slice015.npy\n",
            "Saved 0226_CN001_slice016.npy\n",
            "Saved 0226_CN001_slice017.npy\n",
            "Saved 0226_CN001_slice018.npy\n",
            "Saved 0226_CN001_slice019.npy\n",
            "Saved 0226_CN001_slice020.npy\n",
            "Saved 0226_CN001_slice021.npy\n",
            "Saved 0226_CN001_slice022.npy\n",
            "Saved 0226_CN001_slice023.npy\n",
            "Saved 0226_CN001_slice024.npy\n",
            "Saved 0226_CN001_slice025.npy\n",
            "Saved 0226_CN001_slice026.npy\n",
            "Saved 0226_CN001_slice027.npy\n",
            "Saved 0226_CN001_slice028.npy\n",
            "Saved 0226_CN001_slice029.npy\n",
            "Saved 0226_CN001_slice030.npy\n",
            "Saved 0226_CN001_slice031.npy\n",
            "Saved 0226_CN001_slice032.npy\n",
            "Saved 0226_CN001_slice033.npy\n",
            "Saved 0226_CN001_slice034.npy\n",
            "Saved 0226_CN001_slice035.npy\n",
            "Saved 0226_CN001_slice036.npy\n",
            "Saved 0226_CN001_slice037.npy\n",
            "Saved 0226_CN001_slice038.npy\n",
            "Saved 0226_CN001_slice039.npy\n",
            "Saved 0226_CN001_slice040.npy\n",
            "Saved 0226_CN001_slice041.npy\n",
            "Saved 0226_CN001_slice042.npy\n",
            "Saved 0226_CN001_slice043.npy\n",
            "Saved 0226_CN001_slice044.npy\n",
            "Saved 0226_CN001_slice045.npy\n",
            "Saved 0226_CN001_slice046.npy\n",
            "Saved 0226_CN001_slice047.npy\n",
            "Saved 0226_CN001_slice048.npy\n",
            "Saved 0226_CN001_slice049.npy\n",
            "Saved 0226_CN001_slice050.npy\n",
            "Saved 0239_CN001_slice000.npy\n",
            "Saved 0239_CN001_slice001.npy\n",
            "Saved 0239_CN001_slice002.npy\n",
            "Saved 0239_CN001_slice003.npy\n",
            "Saved 0239_CN001_slice004.npy\n",
            "Saved 0239_CN001_slice005.npy\n",
            "Saved 0239_CN001_slice006.npy\n",
            "Saved 0239_CN001_slice007.npy\n",
            "Saved 0239_CN001_slice008.npy\n",
            "Saved 0239_CN001_slice009.npy\n",
            "Saved 0239_CN001_slice010.npy\n",
            "Saved 0239_CN001_slice011.npy\n",
            "Saved 0239_CN001_slice012.npy\n",
            "Saved 0239_CN001_slice013.npy\n",
            "Saved 0239_CN001_slice014.npy\n",
            "Saved 0239_CN001_slice015.npy\n",
            "Saved 0239_CN001_slice016.npy\n",
            "Saved 0239_CN001_slice017.npy\n",
            "Saved 0239_CN001_slice018.npy\n",
            "Saved 0239_CN001_slice019.npy\n",
            "Saved 0239_CN001_slice020.npy\n",
            "Saved 0239_CN001_slice021.npy\n",
            "Saved 0239_CN001_slice022.npy\n",
            "Saved 0239_CN001_slice023.npy\n",
            "Saved 0239_CN001_slice024.npy\n",
            "Saved 0239_CN001_slice025.npy\n",
            "Saved 0239_CN001_slice026.npy\n",
            "Saved 0239_CN001_slice027.npy\n",
            "Saved 0239_CN001_slice028.npy\n",
            "Saved 0239_CN001_slice029.npy\n",
            "Saved 0239_CN001_slice030.npy\n",
            "Saved 0239_CN001_slice031.npy\n",
            "Saved 0239_CN001_slice032.npy\n",
            "Saved 0239_CN001_slice033.npy\n",
            "Saved 0239_CN001_slice034.npy\n",
            "Saved 0239_CN001_slice035.npy\n",
            "Saved 0239_CN001_slice036.npy\n",
            "Saved 0239_CN001_slice037.npy\n",
            "Saved 0239_CN001_slice038.npy\n",
            "Saved 0239_CN001_slice039.npy\n",
            "Saved 0239_CN001_slice040.npy\n",
            "Saved 0239_CN001_slice041.npy\n",
            "Saved 0239_CN001_slice042.npy\n",
            "Saved 0239_CN001_slice043.npy\n",
            "Saved 0239_CN001_slice044.npy\n",
            "Saved 0239_CN001_slice045.npy\n",
            "Saved 0239_CN001_slice046.npy\n",
            "Saved 0239_CN001_slice047.npy\n",
            "Saved 0239_CN001_slice048.npy\n",
            "Saved 0239_CN001_slice049.npy\n",
            "Saved 0239_CN001_slice050.npy\n",
            "Saved 0253_CN001_slice000.npy\n",
            "Saved 0253_CN001_slice001.npy\n",
            "Saved 0253_CN001_slice002.npy\n",
            "Saved 0253_CN001_slice003.npy\n",
            "Saved 0253_CN001_slice004.npy\n",
            "Saved 0253_CN001_slice005.npy\n",
            "Saved 0253_CN001_slice006.npy\n",
            "Saved 0253_CN001_slice007.npy\n",
            "Saved 0253_CN001_slice008.npy\n",
            "Saved 0253_CN001_slice009.npy\n",
            "Saved 0253_CN001_slice010.npy\n",
            "Saved 0253_CN001_slice011.npy\n",
            "Saved 0253_CN001_slice012.npy\n",
            "Saved 0253_CN001_slice013.npy\n",
            "Saved 0253_CN001_slice014.npy\n",
            "Saved 0253_CN001_slice015.npy\n",
            "Saved 0253_CN001_slice016.npy\n",
            "Saved 0253_CN001_slice017.npy\n",
            "Saved 0253_CN001_slice018.npy\n",
            "Saved 0253_CN001_slice019.npy\n",
            "Saved 0253_CN001_slice020.npy\n",
            "Saved 0253_CN001_slice021.npy\n",
            "Saved 0253_CN001_slice022.npy\n",
            "Saved 0253_CN001_slice023.npy\n",
            "Saved 0253_CN001_slice024.npy\n",
            "Saved 0253_CN001_slice025.npy\n",
            "Saved 0253_CN001_slice026.npy\n",
            "Saved 0253_CN001_slice027.npy\n",
            "Saved 0253_CN001_slice028.npy\n",
            "Saved 0253_CN001_slice029.npy\n",
            "Saved 0253_CN001_slice030.npy\n",
            "Saved 0253_CN001_slice031.npy\n",
            "Saved 0253_CN001_slice032.npy\n",
            "Saved 0253_CN001_slice033.npy\n",
            "Saved 0253_CN001_slice034.npy\n",
            "Saved 0253_CN001_slice035.npy\n",
            "Saved 0253_CN001_slice036.npy\n",
            "Saved 0253_CN001_slice037.npy\n",
            "Saved 0253_CN001_slice038.npy\n",
            "Saved 0253_CN001_slice039.npy\n",
            "Saved 0253_CN001_slice040.npy\n",
            "Saved 0253_CN001_slice041.npy\n",
            "Saved 0253_CN001_slice042.npy\n",
            "Saved 0253_CN001_slice043.npy\n",
            "Saved 0253_CN001_slice044.npy\n",
            "Saved 0253_CN001_slice045.npy\n",
            "Saved 0253_CN001_slice046.npy\n",
            "Saved 0253_CN001_slice047.npy\n",
            "Saved 0253_CN001_slice048.npy\n",
            "Saved 0253_CN001_slice049.npy\n",
            "Saved 0253_CN001_slice050.npy\n",
            "Saved 0261_CN001_slice000.npy\n",
            "Saved 0261_CN001_slice001.npy\n",
            "Saved 0261_CN001_slice002.npy\n",
            "Saved 0261_CN001_slice003.npy\n",
            "Saved 0261_CN001_slice004.npy\n",
            "Saved 0261_CN001_slice005.npy\n",
            "Saved 0261_CN001_slice006.npy\n",
            "Saved 0261_CN001_slice007.npy\n",
            "Saved 0261_CN001_slice008.npy\n",
            "Saved 0261_CN001_slice009.npy\n",
            "Saved 0261_CN001_slice010.npy\n",
            "Saved 0261_CN001_slice011.npy\n",
            "Saved 0261_CN001_slice012.npy\n",
            "Saved 0261_CN001_slice013.npy\n",
            "Saved 0261_CN001_slice014.npy\n",
            "Saved 0261_CN001_slice015.npy\n",
            "Saved 0261_CN001_slice016.npy\n",
            "Saved 0261_CN001_slice017.npy\n",
            "Saved 0261_CN001_slice018.npy\n",
            "Saved 0261_CN001_slice019.npy\n",
            "Saved 0261_CN001_slice020.npy\n",
            "Saved 0261_CN001_slice021.npy\n",
            "Saved 0261_CN001_slice022.npy\n",
            "Saved 0261_CN001_slice023.npy\n",
            "Saved 0261_CN001_slice024.npy\n",
            "Saved 0261_CN001_slice025.npy\n",
            "Saved 0261_CN001_slice026.npy\n",
            "Saved 0261_CN001_slice027.npy\n",
            "Saved 0261_CN001_slice028.npy\n",
            "Saved 0261_CN001_slice029.npy\n",
            "Saved 0261_CN001_slice030.npy\n",
            "Saved 0261_CN001_slice031.npy\n",
            "Saved 0261_CN001_slice032.npy\n",
            "Saved 0261_CN001_slice033.npy\n",
            "Saved 0261_CN001_slice034.npy\n",
            "Saved 0261_CN001_slice035.npy\n",
            "Saved 0261_CN001_slice036.npy\n",
            "Saved 0261_CN001_slice037.npy\n",
            "Saved 0261_CN001_slice038.npy\n",
            "Saved 0261_CN001_slice039.npy\n",
            "Saved 0261_CN001_slice040.npy\n",
            "Saved 0261_CN001_slice041.npy\n",
            "Saved 0261_CN001_slice042.npy\n",
            "Saved 0261_CN001_slice043.npy\n",
            "Saved 0261_CN001_slice044.npy\n",
            "Saved 0261_CN001_slice045.npy\n",
            "Saved 0261_CN001_slice046.npy\n",
            "Saved 0261_CN001_slice047.npy\n",
            "Saved 0261_CN001_slice048.npy\n",
            "Saved 0261_CN001_slice049.npy\n",
            "Saved 0261_CN001_slice050.npy\n",
            "Saved 0279_CN001_slice000.npy\n",
            "Saved 0279_CN001_slice001.npy\n",
            "Saved 0279_CN001_slice002.npy\n",
            "Saved 0279_CN001_slice003.npy\n",
            "Saved 0279_CN001_slice004.npy\n",
            "Saved 0279_CN001_slice005.npy\n",
            "Saved 0279_CN001_slice006.npy\n",
            "Saved 0279_CN001_slice007.npy\n",
            "Saved 0279_CN001_slice008.npy\n",
            "Saved 0279_CN001_slice009.npy\n",
            "Saved 0279_CN001_slice010.npy\n",
            "Saved 0279_CN001_slice011.npy\n",
            "Saved 0279_CN001_slice012.npy\n",
            "Saved 0279_CN001_slice013.npy\n",
            "Saved 0279_CN001_slice014.npy\n",
            "Saved 0279_CN001_slice015.npy\n",
            "Saved 0279_CN001_slice016.npy\n",
            "Saved 0279_CN001_slice017.npy\n",
            "Saved 0279_CN001_slice018.npy\n",
            "Saved 0279_CN001_slice019.npy\n",
            "Saved 0279_CN001_slice020.npy\n",
            "Saved 0279_CN001_slice021.npy\n",
            "Saved 0279_CN001_slice022.npy\n",
            "Saved 0279_CN001_slice023.npy\n",
            "Saved 0279_CN001_slice024.npy\n",
            "Saved 0279_CN001_slice025.npy\n",
            "Saved 0279_CN001_slice026.npy\n",
            "Saved 0279_CN001_slice027.npy\n",
            "Saved 0279_CN001_slice028.npy\n",
            "Saved 0279_CN001_slice029.npy\n",
            "Saved 0279_CN001_slice030.npy\n",
            "Saved 0279_CN001_slice031.npy\n",
            "Saved 0279_CN001_slice032.npy\n",
            "Saved 0279_CN001_slice033.npy\n",
            "Saved 0279_CN001_slice034.npy\n",
            "Saved 0327_CN001_slice000.npy\n",
            "Saved 0327_CN001_slice001.npy\n",
            "Saved 0327_CN001_slice002.npy\n",
            "Saved 0327_CN001_slice003.npy\n",
            "Saved 0327_CN001_slice004.npy\n",
            "Saved 0327_CN001_slice005.npy\n",
            "Saved 0327_CN001_slice006.npy\n",
            "Saved 0327_CN001_slice007.npy\n",
            "Saved 0327_CN001_slice008.npy\n",
            "Saved 0327_CN001_slice009.npy\n",
            "Saved 0327_CN001_slice010.npy\n",
            "Saved 0327_CN001_slice011.npy\n",
            "Saved 0327_CN001_slice012.npy\n",
            "Saved 0327_CN001_slice013.npy\n",
            "Saved 0327_CN001_slice014.npy\n",
            "Saved 0327_CN001_slice015.npy\n",
            "Saved 0327_CN001_slice016.npy\n",
            "Saved 0327_CN001_slice017.npy\n",
            "Saved 0327_CN001_slice018.npy\n",
            "Saved 0327_CN001_slice019.npy\n",
            "Saved 0327_CN001_slice020.npy\n",
            "Saved 0327_CN001_slice021.npy\n",
            "Saved 0327_CN001_slice022.npy\n",
            "Saved 0327_CN001_slice023.npy\n",
            "Saved 0327_CN001_slice024.npy\n",
            "Saved 0327_CN001_slice025.npy\n",
            "Saved 0327_CN001_slice026.npy\n",
            "Saved 0327_CN001_slice027.npy\n",
            "Saved 0327_CN001_slice028.npy\n",
            "Saved 0327_CN001_slice029.npy\n",
            "Saved 0327_CN001_slice030.npy\n",
            "Saved 0327_CN001_slice031.npy\n",
            "Saved 0327_CN001_slice032.npy\n",
            "Saved 0327_CN001_slice033.npy\n",
            "Saved 0327_CN001_slice034.npy\n",
            "Saved 0327_CN001_slice035.npy\n",
            "Saved 0327_CN001_slice036.npy\n",
            "Saved 0327_CN001_slice037.npy\n",
            "Saved 0327_CN001_slice038.npy\n",
            "Saved 0327_CN001_slice039.npy\n",
            "Saved 0327_CN001_slice040.npy\n",
            "Saved 0327_CN001_slice041.npy\n",
            "Saved 0327_CN001_slice042.npy\n",
            "Saved 0327_CN001_slice043.npy\n",
            "Saved 0327_CN001_slice044.npy\n",
            "Saved 0327_CN001_slice045.npy\n",
            "Saved 0327_CN001_slice046.npy\n",
            "Saved 0327_CN001_slice047.npy\n",
            "Saved 0327_CN001_slice048.npy\n",
            "Saved 0327_CN001_slice049.npy\n",
            "Saved 0327_CN001_slice050.npy\n",
            "Saved 0364_CN001_slice000.npy\n",
            "Saved 0364_CN001_slice001.npy\n",
            "Saved 0364_CN001_slice002.npy\n",
            "Saved 0364_CN001_slice003.npy\n",
            "Saved 0364_CN001_slice004.npy\n",
            "Saved 0364_CN001_slice005.npy\n",
            "Saved 0364_CN001_slice006.npy\n",
            "Saved 0364_CN001_slice007.npy\n",
            "Saved 0364_CN001_slice008.npy\n",
            "Saved 0364_CN001_slice009.npy\n",
            "Saved 0364_CN001_slice010.npy\n",
            "Saved 0364_CN001_slice011.npy\n",
            "Saved 0364_CN001_slice012.npy\n",
            "Saved 0364_CN001_slice013.npy\n",
            "Saved 0364_CN001_slice014.npy\n",
            "Saved 0364_CN001_slice015.npy\n",
            "Saved 0364_CN001_slice016.npy\n",
            "Saved 0364_CN001_slice017.npy\n",
            "Saved 0364_CN001_slice018.npy\n",
            "Saved 0364_CN001_slice019.npy\n",
            "Saved 0364_CN001_slice020.npy\n",
            "Saved 0364_CN001_slice021.npy\n",
            "Saved 0364_CN001_slice022.npy\n",
            "Saved 0364_CN001_slice023.npy\n",
            "Saved 0364_CN001_slice024.npy\n",
            "Saved 0364_CN001_slice025.npy\n",
            "Saved 0364_CN001_slice026.npy\n",
            "Saved 0364_CN001_slice027.npy\n",
            "Saved 0364_CN001_slice028.npy\n",
            "Saved 0364_CN001_slice029.npy\n",
            "Saved 0364_CN001_slice030.npy\n",
            "Saved 0364_CN001_slice031.npy\n",
            "Saved 0364_CN001_slice032.npy\n",
            "Saved 0364_CN001_slice033.npy\n",
            "Saved 0364_CN001_slice034.npy\n",
            "Saved 0364_CN001_slice035.npy\n",
            "Saved 0364_CN001_slice036.npy\n",
            "Saved 0364_CN001_slice037.npy\n",
            "Saved 0364_CN001_slice038.npy\n",
            "Saved 0364_CN001_slice039.npy\n",
            "Saved 0364_CN001_slice040.npy\n",
            "Saved 0364_CN001_slice041.npy\n",
            "Saved 0364_CN001_slice042.npy\n",
            "Saved 0364_CN001_slice043.npy\n",
            "Saved 0364_CN001_slice044.npy\n",
            "Saved 0364_CN001_slice045.npy\n",
            "Saved 0364_CN001_slice046.npy\n",
            "Saved 0364_CN001_slice047.npy\n",
            "Saved 0364_CN001_slice048.npy\n",
            "Saved 0364_CN001_slice049.npy\n",
            "Saved 0364_CN001_slice050.npy\n",
            "Saved 0382_CN001_slice000.npy\n",
            "Saved 0382_CN001_slice001.npy\n",
            "Saved 0382_CN001_slice002.npy\n",
            "Saved 0382_CN001_slice003.npy\n",
            "Saved 0382_CN001_slice004.npy\n",
            "Saved 0382_CN001_slice005.npy\n",
            "Saved 0382_CN001_slice006.npy\n",
            "Saved 0382_CN001_slice007.npy\n",
            "Saved 0382_CN001_slice008.npy\n",
            "Saved 0382_CN001_slice009.npy\n",
            "Saved 0382_CN001_slice010.npy\n",
            "Saved 0382_CN001_slice011.npy\n",
            "Saved 0382_CN001_slice012.npy\n",
            "Saved 0382_CN001_slice013.npy\n",
            "Saved 0382_CN001_slice014.npy\n",
            "Saved 0382_CN001_slice015.npy\n",
            "Saved 0382_CN001_slice016.npy\n",
            "Saved 0382_CN001_slice017.npy\n",
            "Saved 0382_CN001_slice018.npy\n",
            "Saved 0382_CN001_slice019.npy\n",
            "Saved 0382_CN001_slice020.npy\n",
            "Saved 0382_CN001_slice021.npy\n",
            "Saved 0382_CN001_slice022.npy\n",
            "Saved 0382_CN001_slice023.npy\n",
            "Saved 0382_CN001_slice024.npy\n",
            "Saved 0382_CN001_slice025.npy\n",
            "Saved 0382_CN001_slice026.npy\n",
            "Saved 0382_CN001_slice027.npy\n",
            "Saved 0382_CN001_slice028.npy\n",
            "Saved 0382_CN001_slice029.npy\n",
            "Saved 0382_CN001_slice030.npy\n",
            "Saved 0382_CN001_slice031.npy\n",
            "Saved 0382_CN001_slice032.npy\n",
            "Saved 0382_CN001_slice033.npy\n",
            "Saved 0382_CN001_slice034.npy\n",
            "Saved 0382_CN001_slice035.npy\n",
            "Saved 0382_CN001_slice036.npy\n",
            "Saved 0382_CN001_slice037.npy\n",
            "Saved 0382_CN001_slice038.npy\n",
            "Saved 0382_CN001_slice039.npy\n",
            "Saved 0382_CN001_slice040.npy\n",
            "Saved 0382_CN001_slice041.npy\n",
            "Saved 0382_CN001_slice042.npy\n",
            "Saved 0382_CN001_slice043.npy\n",
            "Saved 0382_CN001_slice044.npy\n",
            "Saved 0382_CN001_slice045.npy\n",
            "Saved 0382_CN001_slice046.npy\n",
            "Saved 0382_CN001_slice047.npy\n",
            "Saved 0382_CN001_slice048.npy\n",
            "Saved 0382_CN001_slice049.npy\n",
            "Saved 0382_CN001_slice050.npy\n",
            "Saved 0417_CN001_slice000.npy\n",
            "Saved 0417_CN001_slice001.npy\n",
            "Saved 0417_CN001_slice002.npy\n",
            "Saved 0417_CN001_slice003.npy\n",
            "Saved 0417_CN001_slice004.npy\n",
            "Saved 0417_CN001_slice005.npy\n",
            "Saved 0417_CN001_slice006.npy\n",
            "Saved 0417_CN001_slice007.npy\n",
            "Saved 0417_CN001_slice008.npy\n",
            "Saved 0417_CN001_slice009.npy\n",
            "Saved 0417_CN001_slice010.npy\n",
            "Saved 0417_CN001_slice011.npy\n",
            "Saved 0417_CN001_slice012.npy\n",
            "Saved 0417_CN001_slice013.npy\n",
            "Saved 0417_CN001_slice014.npy\n",
            "Saved 0417_CN001_slice015.npy\n",
            "Saved 0417_CN001_slice016.npy\n",
            "Saved 0417_CN001_slice017.npy\n",
            "Saved 0417_CN001_slice018.npy\n",
            "Saved 0417_CN001_slice019.npy\n",
            "Saved 0417_CN001_slice020.npy\n",
            "Saved 0417_CN001_slice021.npy\n",
            "Saved 0417_CN001_slice022.npy\n",
            "Saved 0417_CN001_slice023.npy\n",
            "Saved 0417_CN001_slice024.npy\n",
            "Saved 0417_CN001_slice025.npy\n",
            "Saved 0417_CN001_slice026.npy\n",
            "Saved 0417_CN001_slice027.npy\n",
            "Saved 0417_CN001_slice028.npy\n",
            "Saved 0417_CN001_slice029.npy\n",
            "Saved 0417_CN001_slice030.npy\n",
            "Saved 0417_CN001_slice031.npy\n",
            "Saved 0417_CN001_slice032.npy\n",
            "Saved 0417_CN001_slice033.npy\n",
            "Saved 0417_CN001_slice034.npy\n",
            "Saved 0417_CN001_slice035.npy\n",
            "Saved 0417_CN001_slice036.npy\n",
            "Saved 0417_CN001_slice037.npy\n",
            "Saved 0417_CN001_slice038.npy\n",
            "Saved 0417_CN001_slice039.npy\n",
            "Saved 0417_CN001_slice040.npy\n",
            "Saved 0417_CN001_slice041.npy\n",
            "Saved 0417_CN001_slice042.npy\n",
            "Saved 0417_CN001_slice043.npy\n",
            "Saved 0417_CN001_slice044.npy\n",
            "Saved 0417_CN001_slice045.npy\n",
            "Saved 0417_CN001_slice046.npy\n",
            "Saved 0417_CN001_slice047.npy\n",
            "Saved 0417_CN001_slice048.npy\n",
            "Saved 0417_CN001_slice049.npy\n",
            "Saved 0417_CN001_slice050.npy\n",
            "Saved 0441_CN001_slice000.npy\n",
            "Saved 0441_CN001_slice001.npy\n",
            "Saved 0441_CN001_slice002.npy\n",
            "Saved 0441_CN001_slice003.npy\n",
            "Saved 0441_CN001_slice004.npy\n",
            "Saved 0441_CN001_slice005.npy\n",
            "Saved 0441_CN001_slice006.npy\n",
            "Saved 0441_CN001_slice007.npy\n",
            "Saved 0441_CN001_slice008.npy\n",
            "Saved 0441_CN001_slice009.npy\n",
            "Saved 0441_CN001_slice010.npy\n",
            "Saved 0441_CN001_slice011.npy\n",
            "Saved 0441_CN001_slice012.npy\n",
            "Saved 0441_CN001_slice013.npy\n",
            "Saved 0441_CN001_slice014.npy\n",
            "Saved 0441_CN001_slice015.npy\n",
            "Saved 0441_CN001_slice016.npy\n",
            "Saved 0441_CN001_slice017.npy\n",
            "Saved 0441_CN001_slice018.npy\n",
            "Saved 0441_CN001_slice019.npy\n",
            "Saved 0441_CN001_slice020.npy\n",
            "Saved 0441_CN001_slice021.npy\n",
            "Saved 0441_CN001_slice022.npy\n",
            "Saved 0441_CN001_slice023.npy\n",
            "Saved 0441_CN001_slice024.npy\n",
            "Saved 0441_CN001_slice025.npy\n",
            "Saved 0441_CN001_slice026.npy\n",
            "Saved 0441_CN001_slice027.npy\n",
            "Saved 0441_CN001_slice028.npy\n",
            "Saved 0441_CN001_slice029.npy\n",
            "Saved 0441_CN001_slice030.npy\n",
            "Saved 0441_CN001_slice031.npy\n",
            "Saved 0441_CN001_slice032.npy\n",
            "Saved 0441_CN001_slice033.npy\n",
            "Saved 0441_CN001_slice034.npy\n",
            "Saved 0441_CN001_slice035.npy\n",
            "Saved 0441_CN001_slice036.npy\n",
            "Saved 0441_CN001_slice037.npy\n",
            "Saved 0441_CN001_slice038.npy\n",
            "Saved 0441_CN001_slice039.npy\n",
            "Saved 0441_CN001_slice040.npy\n",
            "Saved 0441_CN001_slice041.npy\n",
            "Saved 0441_CN001_slice042.npy\n",
            "Saved 0441_CN001_slice043.npy\n",
            "Saved 0441_CN001_slice044.npy\n",
            "Saved 0441_CN001_slice045.npy\n",
            "Saved 0441_CN001_slice046.npy\n",
            "Saved 0441_CN001_slice047.npy\n",
            "Saved 0441_CN001_slice048.npy\n",
            "Saved 0441_CN001_slice049.npy\n",
            "Saved 0441_CN001_slice050.npy\n",
            "Saved 0446_CN001_slice000.npy\n",
            "Saved 0446_CN001_slice001.npy\n",
            "Saved 0446_CN001_slice002.npy\n",
            "Saved 0446_CN001_slice003.npy\n",
            "Saved 0446_CN001_slice004.npy\n",
            "Saved 0446_CN001_slice005.npy\n",
            "Saved 0446_CN001_slice006.npy\n",
            "Saved 0446_CN001_slice007.npy\n",
            "Saved 0446_CN001_slice008.npy\n",
            "Saved 0446_CN001_slice009.npy\n",
            "Saved 0446_CN001_slice010.npy\n",
            "Saved 0446_CN001_slice011.npy\n",
            "Saved 0446_CN001_slice012.npy\n",
            "Saved 0446_CN001_slice013.npy\n",
            "Saved 0446_CN001_slice014.npy\n",
            "Saved 0446_CN001_slice015.npy\n",
            "Saved 0446_CN001_slice016.npy\n",
            "Saved 0446_CN001_slice017.npy\n",
            "Saved 0446_CN001_slice018.npy\n",
            "Saved 0446_CN001_slice019.npy\n",
            "Saved 0446_CN001_slice020.npy\n",
            "Saved 0446_CN001_slice021.npy\n",
            "Saved 0446_CN001_slice022.npy\n",
            "Saved 0446_CN001_slice023.npy\n",
            "Saved 0446_CN001_slice024.npy\n",
            "Saved 0446_CN001_slice025.npy\n",
            "Saved 0446_CN001_slice026.npy\n",
            "Saved 0446_CN001_slice027.npy\n",
            "Saved 0446_CN001_slice028.npy\n",
            "Saved 0446_CN001_slice029.npy\n",
            "Saved 0446_CN001_slice030.npy\n",
            "Saved 0446_CN001_slice031.npy\n",
            "Saved 0446_CN001_slice032.npy\n",
            "Saved 0446_CN001_slice033.npy\n",
            "Saved 0446_CN001_slice034.npy\n",
            "Saved 0446_CN001_slice035.npy\n",
            "Saved 0446_CN001_slice036.npy\n",
            "Saved 0446_CN001_slice037.npy\n",
            "Saved 0446_CN001_slice038.npy\n",
            "Saved 0446_CN001_slice039.npy\n",
            "Saved 0446_CN001_slice040.npy\n",
            "Saved 0446_CN001_slice041.npy\n",
            "Saved 0446_CN001_slice042.npy\n",
            "Saved 0446_CN001_slice043.npy\n",
            "Saved 0446_CN001_slice044.npy\n",
            "Saved 0446_CN001_slice045.npy\n",
            "Saved 0446_CN001_slice046.npy\n",
            "Saved 0446_CN001_slice047.npy\n",
            "Saved 0446_CN001_slice048.npy\n",
            "Saved 0446_CN001_slice049.npy\n",
            "Saved 0446_CN001_slice050.npy\n",
            "Saved 0472_CN001_slice000.npy\n",
            "Saved 0472_CN001_slice001.npy\n",
            "Saved 0472_CN001_slice002.npy\n",
            "Saved 0472_CN001_slice003.npy\n",
            "Saved 0472_CN001_slice004.npy\n",
            "Saved 0472_CN001_slice005.npy\n",
            "Saved 0472_CN001_slice006.npy\n",
            "Saved 0472_CN001_slice007.npy\n",
            "Saved 0472_CN001_slice008.npy\n",
            "Saved 0472_CN001_slice009.npy\n",
            "Saved 0472_CN001_slice010.npy\n",
            "Saved 0472_CN001_slice011.npy\n",
            "Saved 0472_CN001_slice012.npy\n",
            "Saved 0472_CN001_slice013.npy\n",
            "Saved 0472_CN001_slice014.npy\n",
            "Saved 0472_CN001_slice015.npy\n",
            "Saved 0472_CN001_slice016.npy\n",
            "Saved 0472_CN001_slice017.npy\n",
            "Saved 0472_CN001_slice018.npy\n",
            "Saved 0472_CN001_slice019.npy\n",
            "Saved 0472_CN001_slice020.npy\n",
            "Saved 0472_CN001_slice021.npy\n",
            "Saved 0472_CN001_slice022.npy\n",
            "Saved 0472_CN001_slice023.npy\n",
            "Saved 0472_CN001_slice024.npy\n",
            "Saved 0472_CN001_slice025.npy\n",
            "Saved 0472_CN001_slice026.npy\n",
            "Saved 0472_CN001_slice027.npy\n",
            "Saved 0472_CN001_slice028.npy\n",
            "Saved 0472_CN001_slice029.npy\n",
            "Saved 0472_CN001_slice030.npy\n",
            "Saved 0472_CN001_slice031.npy\n",
            "Saved 0472_CN001_slice032.npy\n",
            "Saved 0472_CN001_slice033.npy\n",
            "Saved 0472_CN001_slice034.npy\n",
            "Saved 0472_CN001_slice035.npy\n",
            "Saved 0472_CN001_slice036.npy\n",
            "Saved 0472_CN001_slice037.npy\n",
            "Saved 0472_CN001_slice038.npy\n",
            "Saved 0472_CN001_slice039.npy\n",
            "Saved 0472_CN001_slice040.npy\n",
            "Saved 0472_CN001_slice041.npy\n",
            "Saved 0472_CN001_slice042.npy\n",
            "Saved 0472_CN001_slice043.npy\n",
            "Saved 0472_CN001_slice044.npy\n",
            "Saved 0472_CN001_slice045.npy\n",
            "Saved 0472_CN001_slice046.npy\n",
            "Saved 0472_CN001_slice047.npy\n",
            "Saved 0472_CN001_slice048.npy\n",
            "Saved 0472_CN001_slice049.npy\n",
            "Saved 0472_CN001_slice050.npy\n",
            "Saved 0514_CN001_slice000.npy\n",
            "Saved 0514_CN001_slice001.npy\n",
            "Saved 0514_CN001_slice002.npy\n",
            "Saved 0514_CN001_slice003.npy\n",
            "Saved 0514_CN001_slice004.npy\n",
            "Saved 0514_CN001_slice005.npy\n",
            "Saved 0514_CN001_slice006.npy\n",
            "Saved 0514_CN001_slice007.npy\n",
            "Saved 0514_CN001_slice008.npy\n",
            "Saved 0514_CN001_slice009.npy\n",
            "Saved 0514_CN001_slice010.npy\n",
            "Saved 0514_CN001_slice011.npy\n",
            "Saved 0514_CN001_slice012.npy\n",
            "Saved 0514_CN001_slice013.npy\n",
            "Saved 0514_CN001_slice014.npy\n",
            "Saved 0514_CN001_slice015.npy\n",
            "Saved 0514_CN001_slice016.npy\n",
            "Saved 0514_CN001_slice017.npy\n",
            "Saved 0514_CN001_slice018.npy\n",
            "Saved 0514_CN001_slice019.npy\n",
            "Saved 0514_CN001_slice020.npy\n",
            "Saved 0514_CN001_slice021.npy\n",
            "Saved 0514_CN001_slice022.npy\n",
            "Saved 0514_CN001_slice023.npy\n",
            "Saved 0514_CN001_slice024.npy\n",
            "Saved 0514_CN001_slice025.npy\n",
            "Saved 0514_CN001_slice026.npy\n",
            "Saved 0514_CN001_slice027.npy\n",
            "Saved 0514_CN001_slice028.npy\n",
            "Saved 0514_CN001_slice029.npy\n",
            "Saved 0514_CN001_slice030.npy\n",
            "Saved 0514_CN001_slice031.npy\n",
            "Saved 0514_CN001_slice032.npy\n",
            "Saved 0514_CN001_slice033.npy\n",
            "Saved 0514_CN001_slice034.npy\n",
            "Saved 0514_CN001_slice035.npy\n",
            "Saved 0514_CN001_slice036.npy\n",
            "Saved 0514_CN001_slice037.npy\n",
            "Saved 0514_CN001_slice038.npy\n",
            "Saved 0514_CN001_slice039.npy\n",
            "Saved 0514_CN001_slice040.npy\n",
            "Saved 0514_CN001_slice041.npy\n",
            "Saved 0514_CN001_slice042.npy\n",
            "Saved 0062_CN001_slice000.npy\n",
            "Saved 0062_CN001_slice001.npy\n",
            "Saved 0062_CN001_slice002.npy\n",
            "Saved 0062_CN001_slice003.npy\n",
            "Saved 0062_CN001_slice004.npy\n",
            "Saved 0062_CN001_slice005.npy\n",
            "Saved 0062_CN001_slice006.npy\n",
            "Saved 0062_CN001_slice007.npy\n",
            "Saved 0062_CN001_slice008.npy\n",
            "Saved 0062_CN001_slice009.npy\n",
            "Saved 0062_CN001_slice010.npy\n",
            "Saved 0062_CN001_slice011.npy\n",
            "Saved 0062_CN001_slice012.npy\n",
            "Saved 0062_CN001_slice013.npy\n",
            "Saved 0062_CN001_slice014.npy\n",
            "Saved 0062_CN001_slice015.npy\n",
            "Saved 0062_CN001_slice016.npy\n",
            "Saved 0062_CN001_slice017.npy\n",
            "Saved 0062_CN001_slice018.npy\n",
            "Saved 0062_CN001_slice019.npy\n",
            "Saved 0062_CN001_slice020.npy\n",
            "Saved 0062_CN001_slice021.npy\n",
            "Saved 0062_CN001_slice022.npy\n",
            "Saved 0062_CN001_slice023.npy\n",
            "Saved 0062_CN001_slice024.npy\n",
            "Saved 0062_CN001_slice025.npy\n",
            "Saved 0062_CN001_slice026.npy\n",
            "Saved 0062_CN001_slice027.npy\n",
            "Saved 0062_CN001_slice028.npy\n",
            "Saved 0062_CN001_slice029.npy\n",
            "Saved 0062_CN001_slice030.npy\n",
            "Saved 0062_CN001_slice031.npy\n",
            "Saved 0062_CN001_slice032.npy\n",
            "Saved 0062_CN001_slice033.npy\n",
            "Saved 0062_CN001_slice034.npy\n",
            "Saved 0062_CN001_slice035.npy\n",
            "Saved 0062_CN001_slice036.npy\n",
            "Saved 0062_CN001_slice037.npy\n",
            "Saved 0062_CN001_slice038.npy\n",
            "Saved 0062_CN001_slice039.npy\n",
            "Saved 0062_CN001_slice040.npy\n",
            "Saved 0062_CN001_slice041.npy\n",
            "Saved 0062_CN001_slice042.npy\n",
            "Saved 0062_CN001_slice043.npy\n",
            "Saved 0062_CN001_slice044.npy\n",
            "Saved 0062_CN001_slice045.npy\n",
            "Saved 0062_CN001_slice046.npy\n",
            "Saved 0062_CN001_slice047.npy\n",
            "Saved 0062_CN001_slice048.npy\n",
            "Saved 0062_CN001_slice049.npy\n",
            "Saved 0062_CN001_slice050.npy\n",
            "Saved 0197_CN001_slice000.npy\n",
            "Saved 0197_CN001_slice001.npy\n",
            "Saved 0197_CN001_slice002.npy\n",
            "Saved 0197_CN001_slice003.npy\n",
            "Saved 0197_CN001_slice004.npy\n",
            "Saved 0197_CN001_slice005.npy\n",
            "Saved 0197_CN001_slice006.npy\n",
            "Saved 0197_CN001_slice007.npy\n",
            "Saved 0197_CN001_slice008.npy\n",
            "Saved 0197_CN001_slice009.npy\n",
            "Saved 0197_CN001_slice010.npy\n",
            "Saved 0197_CN001_slice011.npy\n",
            "Saved 0197_CN001_slice012.npy\n",
            "Saved 0197_CN001_slice013.npy\n",
            "Saved 0197_CN001_slice014.npy\n",
            "Saved 0197_CN001_slice015.npy\n",
            "Saved 0197_CN001_slice016.npy\n",
            "Saved 0197_CN001_slice017.npy\n",
            "Saved 0197_CN001_slice018.npy\n",
            "Saved 0197_CN001_slice019.npy\n",
            "Saved 0197_CN001_slice020.npy\n",
            "Saved 0197_CN001_slice021.npy\n",
            "Saved 0197_CN001_slice022.npy\n",
            "Saved 0197_CN001_slice023.npy\n",
            "Saved 0197_CN001_slice024.npy\n",
            "Saved 0197_CN001_slice025.npy\n",
            "Saved 0197_CN001_slice026.npy\n",
            "Saved 0197_CN001_slice027.npy\n",
            "Saved 0197_CN001_slice028.npy\n",
            "Saved 0197_CN001_slice029.npy\n",
            "Saved 0197_CN001_slice030.npy\n",
            "Saved 0197_CN001_slice031.npy\n",
            "Saved 0197_CN001_slice032.npy\n",
            "Saved 0197_CN001_slice033.npy\n",
            "Saved 0197_CN001_slice034.npy\n",
            "Saved 0197_CN001_slice035.npy\n",
            "Saved 0197_CN001_slice036.npy\n",
            "Saved 0197_CN001_slice037.npy\n",
            "Saved 0197_CN001_slice038.npy\n",
            "Saved 0197_CN001_slice039.npy\n",
            "Saved 0197_CN001_slice040.npy\n",
            "Saved 0197_CN001_slice041.npy\n",
            "Saved 0197_CN001_slice042.npy\n",
            "Saved 0197_CN001_slice043.npy\n",
            "Saved 0197_CN001_slice044.npy\n",
            "Saved 0197_CN001_slice045.npy\n",
            "Saved 0197_CN001_slice046.npy\n",
            "Saved 0197_CN001_slice047.npy\n",
            "Saved 0197_CN001_slice048.npy\n",
            "Saved 0197_CN001_slice049.npy\n",
            "Saved 0197_CN001_slice050.npy\n",
            "Saved 0214_CN001_slice000.npy\n",
            "Saved 0214_CN001_slice001.npy\n",
            "Saved 0214_CN001_slice002.npy\n",
            "Saved 0214_CN001_slice003.npy\n",
            "Saved 0214_CN001_slice004.npy\n",
            "Saved 0214_CN001_slice005.npy\n",
            "Saved 0214_CN001_slice006.npy\n",
            "Saved 0214_CN001_slice007.npy\n",
            "Saved 0214_CN001_slice008.npy\n",
            "Saved 0214_CN001_slice009.npy\n",
            "Saved 0214_CN001_slice010.npy\n",
            "Saved 0214_CN001_slice011.npy\n",
            "Saved 0214_CN001_slice012.npy\n",
            "Saved 0214_CN001_slice013.npy\n",
            "Saved 0214_CN001_slice014.npy\n",
            "Saved 0214_CN001_slice015.npy\n",
            "Saved 0214_CN001_slice016.npy\n",
            "Saved 0214_CN001_slice017.npy\n",
            "Saved 0214_CN001_slice018.npy\n",
            "Saved 0214_CN001_slice019.npy\n",
            "Saved 0214_CN001_slice020.npy\n",
            "Saved 0214_CN001_slice021.npy\n",
            "Saved 0214_CN001_slice022.npy\n",
            "Saved 0214_CN001_slice023.npy\n",
            "Saved 0214_CN001_slice024.npy\n",
            "Saved 0214_CN001_slice025.npy\n",
            "Saved 0214_CN001_slice026.npy\n",
            "Saved 0214_CN001_slice027.npy\n",
            "Saved 0214_CN001_slice028.npy\n",
            "Saved 0214_CN001_slice029.npy\n",
            "Saved 0214_CN001_slice030.npy\n",
            "Saved 0214_CN001_slice031.npy\n",
            "Saved 0214_CN001_slice032.npy\n",
            "Saved 0214_CN001_slice033.npy\n",
            "Saved 0214_CN001_slice034.npy\n",
            "Saved 0214_CN001_slice035.npy\n",
            "Saved 0214_CN001_slice036.npy\n",
            "Saved 0214_CN001_slice037.npy\n",
            "Saved 0214_CN001_slice038.npy\n",
            "Saved 0214_CN001_slice039.npy\n",
            "Saved 0214_CN001_slice040.npy\n",
            "Saved 0214_CN001_slice041.npy\n",
            "Saved 0214_CN001_slice042.npy\n",
            "Saved 0214_CN001_slice043.npy\n",
            "Saved 0214_CN001_slice044.npy\n",
            "Saved 0214_CN001_slice045.npy\n",
            "Saved 0214_CN001_slice046.npy\n",
            "Saved 0214_CN001_slice047.npy\n",
            "Saved 0214_CN001_slice048.npy\n",
            "Saved 0214_CN001_slice049.npy\n",
            "Saved 0214_CN001_slice050.npy\n",
            "Saved 0306_CN001_slice000.npy\n",
            "Saved 0306_CN001_slice001.npy\n",
            "Saved 0306_CN001_slice002.npy\n",
            "Saved 0306_CN001_slice003.npy\n",
            "Saved 0306_CN001_slice004.npy\n",
            "Saved 0306_CN001_slice005.npy\n",
            "Saved 0306_CN001_slice006.npy\n",
            "Saved 0306_CN001_slice007.npy\n",
            "Saved 0306_CN001_slice008.npy\n",
            "Saved 0306_CN001_slice009.npy\n",
            "Saved 0306_CN001_slice010.npy\n",
            "Saved 0306_CN001_slice011.npy\n",
            "Saved 0306_CN001_slice012.npy\n",
            "Saved 0306_CN001_slice013.npy\n",
            "Saved 0306_CN001_slice014.npy\n",
            "Saved 0306_CN001_slice015.npy\n",
            "Saved 0306_CN001_slice016.npy\n",
            "Saved 0306_CN001_slice017.npy\n",
            "Saved 0306_CN001_slice018.npy\n",
            "Saved 0306_CN001_slice019.npy\n",
            "Saved 0306_CN001_slice020.npy\n",
            "Saved 0306_CN001_slice021.npy\n",
            "Saved 0306_CN001_slice022.npy\n",
            "Saved 0306_CN001_slice023.npy\n",
            "Saved 0306_CN001_slice024.npy\n",
            "Saved 0306_CN001_slice025.npy\n",
            "Saved 0306_CN001_slice026.npy\n",
            "Saved 0306_CN001_slice027.npy\n",
            "Saved 0306_CN001_slice028.npy\n",
            "Saved 0306_CN001_slice029.npy\n",
            "Saved 0306_CN001_slice030.npy\n",
            "Saved 0306_CN001_slice031.npy\n",
            "Saved 0306_CN001_slice032.npy\n",
            "Saved 0306_CN001_slice033.npy\n",
            "Saved 0306_CN001_slice034.npy\n",
            "Saved 0306_CN001_slice035.npy\n",
            "Saved 0306_CN001_slice036.npy\n",
            "Saved 0306_CN001_slice037.npy\n",
            "Saved 0306_CN001_slice038.npy\n",
            "Saved 0306_CN001_slice039.npy\n",
            "Saved 0306_CN001_slice040.npy\n",
            "Saved 0306_CN001_slice041.npy\n",
            "Saved 0306_CN001_slice042.npy\n",
            "Saved 0306_CN001_slice043.npy\n",
            "Saved 0306_CN001_slice044.npy\n",
            "Saved 0306_CN001_slice045.npy\n",
            "Saved 0306_CN001_slice046.npy\n",
            "Saved 0306_CN001_slice047.npy\n",
            "Saved 0306_CN001_slice048.npy\n",
            "Saved 0306_CN001_slice049.npy\n",
            "Saved 0306_CN001_slice050.npy\n",
            "Saved 0336_CN001_slice000.npy\n",
            "Saved 0336_CN001_slice001.npy\n",
            "Saved 0336_CN001_slice002.npy\n",
            "Saved 0336_CN001_slice003.npy\n",
            "Saved 0336_CN001_slice004.npy\n",
            "Saved 0336_CN001_slice005.npy\n",
            "Saved 0336_CN001_slice006.npy\n",
            "Saved 0336_CN001_slice007.npy\n",
            "Saved 0336_CN001_slice008.npy\n",
            "Saved 0336_CN001_slice009.npy\n",
            "Saved 0336_CN001_slice010.npy\n",
            "Saved 0336_CN001_slice011.npy\n",
            "Saved 0336_CN001_slice012.npy\n",
            "Saved 0336_CN001_slice013.npy\n",
            "Saved 0336_CN001_slice014.npy\n",
            "Saved 0336_CN001_slice015.npy\n",
            "Saved 0336_CN001_slice016.npy\n",
            "Saved 0336_CN001_slice017.npy\n",
            "Saved 0336_CN001_slice018.npy\n",
            "Saved 0336_CN001_slice019.npy\n",
            "Saved 0336_CN001_slice020.npy\n",
            "Saved 0336_CN001_slice021.npy\n",
            "Saved 0336_CN001_slice022.npy\n",
            "Saved 0336_CN001_slice023.npy\n",
            "Saved 0336_CN001_slice024.npy\n",
            "Saved 0336_CN001_slice025.npy\n",
            "Saved 0336_CN001_slice026.npy\n",
            "Saved 0336_CN001_slice027.npy\n",
            "Saved 0336_CN001_slice028.npy\n",
            "Saved 0336_CN001_slice029.npy\n",
            "Saved 0336_CN001_slice030.npy\n",
            "Saved 0336_CN001_slice031.npy\n",
            "Saved 0336_CN001_slice032.npy\n",
            "Saved 0336_CN001_slice033.npy\n",
            "Saved 0336_CN001_slice034.npy\n",
            "Saved 0336_CN001_slice035.npy\n",
            "Saved 0336_CN001_slice036.npy\n",
            "Saved 0336_CN001_slice037.npy\n",
            "Saved 0336_CN001_slice038.npy\n",
            "Saved 0336_CN001_slice039.npy\n",
            "Saved 0336_CN001_slice040.npy\n",
            "Saved 0336_CN001_slice041.npy\n",
            "Saved 0336_CN001_slice042.npy\n",
            "Saved 0336_CN001_slice043.npy\n",
            "Saved 0336_CN001_slice044.npy\n",
            "Saved 0336_CN001_slice045.npy\n",
            "Saved 0336_CN001_slice046.npy\n",
            "Saved 0336_CN001_slice047.npy\n",
            "Saved 0336_CN001_slice048.npy\n",
            "Saved 0336_CN001_slice049.npy\n",
            "Saved 0336_CN001_slice050.npy\n",
            "Saved 0349_CN001_slice000.npy\n",
            "Saved 0349_CN001_slice001.npy\n",
            "Saved 0349_CN001_slice002.npy\n",
            "Saved 0349_CN001_slice003.npy\n",
            "Saved 0349_CN001_slice004.npy\n",
            "Saved 0349_CN001_slice005.npy\n",
            "Saved 0349_CN001_slice006.npy\n",
            "Saved 0349_CN001_slice007.npy\n",
            "Saved 0349_CN001_slice008.npy\n",
            "Saved 0349_CN001_slice009.npy\n",
            "Saved 0349_CN001_slice010.npy\n",
            "Saved 0349_CN001_slice011.npy\n",
            "Saved 0349_CN001_slice012.npy\n",
            "Saved 0349_CN001_slice013.npy\n",
            "Saved 0349_CN001_slice014.npy\n",
            "Saved 0349_CN001_slice015.npy\n",
            "Saved 0349_CN001_slice016.npy\n",
            "Saved 0349_CN001_slice017.npy\n",
            "Saved 0349_CN001_slice018.npy\n",
            "Saved 0349_CN001_slice019.npy\n",
            "Saved 0349_CN001_slice020.npy\n",
            "Saved 0349_CN001_slice021.npy\n",
            "Saved 0349_CN001_slice022.npy\n",
            "Saved 0349_CN001_slice023.npy\n",
            "Saved 0349_CN001_slice024.npy\n",
            "Saved 0349_CN001_slice025.npy\n",
            "Saved 0349_CN001_slice026.npy\n",
            "Saved 0349_CN001_slice027.npy\n",
            "Saved 0349_CN001_slice028.npy\n",
            "Saved 0349_CN001_slice029.npy\n",
            "Saved 0349_CN001_slice030.npy\n",
            "Saved 0349_CN001_slice031.npy\n",
            "Saved 0349_CN001_slice032.npy\n",
            "Saved 0349_CN001_slice033.npy\n",
            "Saved 0349_CN001_slice034.npy\n",
            "Saved 0349_CN001_slice035.npy\n",
            "Saved 0349_CN001_slice036.npy\n",
            "Saved 0349_CN001_slice037.npy\n",
            "Saved 0349_CN001_slice038.npy\n",
            "Saved 0349_CN001_slice039.npy\n",
            "Saved 0349_CN001_slice040.npy\n",
            "Saved 0349_CN001_slice041.npy\n",
            "Saved 0349_CN001_slice042.npy\n",
            "Saved 0349_CN001_slice043.npy\n",
            "Saved 0349_CN001_slice044.npy\n",
            "Saved 0349_CN001_slice045.npy\n",
            "Saved 0349_CN001_slice046.npy\n",
            "Saved 0349_CN001_slice047.npy\n",
            "Saved 0349_CN001_slice048.npy\n",
            "Saved 0349_CN001_slice049.npy\n",
            "Saved 0349_CN001_slice050.npy\n",
            "Saved 0361_CN001_slice000.npy\n",
            "Saved 0361_CN001_slice001.npy\n",
            "Saved 0361_CN001_slice002.npy\n",
            "Saved 0361_CN001_slice003.npy\n",
            "Saved 0361_CN001_slice004.npy\n",
            "Saved 0361_CN001_slice005.npy\n",
            "Saved 0361_CN001_slice006.npy\n",
            "Saved 0361_CN001_slice007.npy\n",
            "Saved 0361_CN001_slice008.npy\n",
            "Saved 0361_CN001_slice009.npy\n",
            "Saved 0361_CN001_slice010.npy\n",
            "Saved 0361_CN001_slice011.npy\n",
            "Saved 0361_CN001_slice012.npy\n",
            "Saved 0361_CN001_slice013.npy\n",
            "Saved 0361_CN001_slice014.npy\n",
            "Saved 0361_CN001_slice015.npy\n",
            "Saved 0361_CN001_slice016.npy\n",
            "Saved 0361_CN001_slice017.npy\n",
            "Saved 0361_CN001_slice018.npy\n",
            "Saved 0361_CN001_slice019.npy\n",
            "Saved 0361_CN001_slice020.npy\n",
            "Saved 0361_CN001_slice021.npy\n",
            "Saved 0361_CN001_slice022.npy\n",
            "Saved 0361_CN001_slice023.npy\n",
            "Saved 0361_CN001_slice024.npy\n",
            "Saved 0361_CN001_slice025.npy\n",
            "Saved 0361_CN001_slice026.npy\n",
            "Saved 0361_CN001_slice027.npy\n",
            "Saved 0361_CN001_slice028.npy\n",
            "Saved 0361_CN001_slice029.npy\n",
            "Saved 0361_CN001_slice030.npy\n",
            "Saved 0361_CN001_slice031.npy\n",
            "Saved 0361_CN001_slice032.npy\n",
            "Saved 0361_CN001_slice033.npy\n",
            "Saved 0361_CN001_slice034.npy\n",
            "Saved 0361_CN001_slice035.npy\n",
            "Saved 0361_CN001_slice036.npy\n",
            "Saved 0361_CN001_slice037.npy\n",
            "Saved 0361_CN001_slice038.npy\n",
            "Saved 0361_CN001_slice039.npy\n",
            "Saved 0361_CN001_slice040.npy\n",
            "Saved 0361_CN001_slice041.npy\n",
            "Saved 0361_CN001_slice042.npy\n",
            "Saved 0361_CN001_slice043.npy\n",
            "Saved 0361_CN001_slice044.npy\n",
            "Saved 0361_CN001_slice045.npy\n",
            "Saved 0361_CN001_slice046.npy\n",
            "Saved 0361_CN001_slice047.npy\n",
            "Saved 0361_CN001_slice048.npy\n",
            "Saved 0361_CN001_slice049.npy\n",
            "Saved 0361_CN001_slice050.npy\n",
            "Saved 0383_CN001_slice000.npy\n",
            "Saved 0383_CN001_slice001.npy\n",
            "Saved 0383_CN001_slice002.npy\n",
            "Saved 0383_CN001_slice003.npy\n",
            "Saved 0383_CN001_slice004.npy\n",
            "Saved 0383_CN001_slice005.npy\n",
            "Saved 0383_CN001_slice006.npy\n",
            "Saved 0383_CN001_slice007.npy\n",
            "Saved 0383_CN001_slice008.npy\n",
            "Saved 0383_CN001_slice009.npy\n",
            "Saved 0383_CN001_slice010.npy\n",
            "Saved 0383_CN001_slice011.npy\n",
            "Saved 0383_CN001_slice012.npy\n",
            "Saved 0383_CN001_slice013.npy\n",
            "Saved 0383_CN001_slice014.npy\n",
            "Saved 0383_CN001_slice015.npy\n",
            "Saved 0383_CN001_slice016.npy\n",
            "Saved 0383_CN001_slice017.npy\n",
            "Saved 0383_CN001_slice018.npy\n",
            "Saved 0383_CN001_slice019.npy\n",
            "Saved 0383_CN001_slice020.npy\n",
            "Saved 0383_CN001_slice021.npy\n",
            "Saved 0383_CN001_slice022.npy\n",
            "Saved 0383_CN001_slice023.npy\n",
            "Saved 0383_CN001_slice024.npy\n",
            "Saved 0383_CN001_slice025.npy\n",
            "Saved 0383_CN001_slice026.npy\n",
            "Saved 0383_CN001_slice027.npy\n",
            "Saved 0383_CN001_slice028.npy\n",
            "Saved 0383_CN001_slice029.npy\n",
            "Saved 0383_CN001_slice030.npy\n",
            "Saved 0383_CN001_slice031.npy\n",
            "Saved 0383_CN001_slice032.npy\n",
            "Saved 0383_CN001_slice033.npy\n",
            "Saved 0383_CN001_slice034.npy\n",
            "Saved 0383_CN001_slice035.npy\n",
            "Saved 0383_CN001_slice036.npy\n",
            "Saved 0383_CN001_slice037.npy\n",
            "Saved 0383_CN001_slice038.npy\n",
            "Saved 0383_CN001_slice039.npy\n",
            "Saved 0383_CN001_slice040.npy\n",
            "Saved 0383_CN001_slice041.npy\n",
            "Saved 0383_CN001_slice042.npy\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# with open(data_label+'train.txt','wb') as fp:\n",
        "#     pickle.dump(train_label,fp)\n",
        "# with open(data_label+'val.txt','wb') as fp:\n",
        "#     pickle.dump(val_label,fp)\n",
        "# with open(data_label+'test.txt','wb') as fp:\n",
        "#     pickle.dump(test_label,fp)"
      ],
      "metadata": {
        "id": "bpHDIV55CNQa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# clean_train_label = clean_train_label[:800]\n",
        "# clean_val_label = clean_val_label[:400]\n",
        "# clean_test_label = clean_test_label[:400]\n",
        "\n",
        "# with open(data_label+'clean_train.txt','wb') as fp:\n",
        "#     pickle.dump(clean_train_label,fp)\n",
        "# with open(data_label+'clean_val.txt','wb') as fp:\n",
        "#     pickle.dump(clean_val_label,fp)\n",
        "# with open(data_label+'clean_test.txt','wb') as fp:\n",
        "#     pickle.dump(clean_test_label,fp)      "
      ],
      "metadata": {
        "id": "iRFVcHqACVLr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# print(\"TOTAL OF CANCER: {}, NON-CANCEROUS:{} IMAGES WERE SAVED FOR TRAIN\".format(np.sum(train_label),len(train_label)-np.sum(train_label)))\n",
        "# print(\"TOTAL OF CANCER: {}, NON-CANCEROUS:{} IMAGES WERE SAVED FOR VAL\".format(np.sum(val_label),len(val_label)-np.sum(val_label)))\n",
        "# print(\"TOTAL OF CANCER: {}, NON-CANCEROUS:{} IMAGES WERE SAVED FOR TEST\".format(np.sum(test_label),len(test_label)-np.sum(test_label)))\n",
        "\n",
        "# print(\"AS THE DATA IS IMBALANCED, WE ADDED CLEAN IMAGES AS FOLLOWING\")\n",
        "# print(\"TRAIN: {}, VAL: {}, TEST: {}\".format(len(clean_train_label),len(clean_val_label),len(clean_test_label)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r5IZ0878CcAC",
        "outputId": "c46b6640-b0c1-4e34-8768-fdf99d5bb59d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TOTAL OF CANCER: 3146, NON-CANCEROUS:1974 IMAGES WERE SAVED FOR TRAIN\n",
            "TOTAL OF CANCER: 914, NON-CANCEROUS:728 IMAGES WERE SAVED FOR VAL\n",
            "TOTAL OF CANCER: 1189, NON-CANCEROUS:572 IMAGES WERE SAVED FOR TEST\n",
            "AS THE DATA IS IMBALANCED, WE ADDED CLEAN IMAGES AS FOLLOWING\n",
            "TRAIN: 800, VAL: 400, TEST: 400\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **CLASSIFIER DATASET**"
      ],
      "metadata": {
        "id": "yQmtOv3ZyXSq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install albumentations==0.4.6"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ycg1YphaDMIt",
        "outputId": "a91106f0-792c-46a9-bb7a-e4c587d2167b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting albumentations==0.4.6\n",
            "  Downloading albumentations-0.4.6.tar.gz (117 kB)\n",
            "\u001b[K     |████████████████████████████████| 117 kB 4.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.11.1 in /usr/local/lib/python3.7/dist-packages (from albumentations==0.4.6) (1.21.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from albumentations==0.4.6) (1.4.1)\n",
            "Collecting imgaug>=0.4.0\n",
            "  Downloading imgaug-0.4.0-py2.py3-none-any.whl (948 kB)\n",
            "\u001b[K     |████████████████████████████████| 948 kB 29.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from albumentations==0.4.6) (3.13)\n",
            "Requirement already satisfied: opencv-python>=4.1.1 in /usr/local/lib/python3.7/dist-packages (from albumentations==0.4.6) (4.1.2.30)\n",
            "Requirement already satisfied: Shapely in /usr/local/lib/python3.7/dist-packages (from imgaug>=0.4.0->albumentations==0.4.6) (1.8.1.post1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from imgaug>=0.4.0->albumentations==0.4.6) (1.15.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from imgaug>=0.4.0->albumentations==0.4.6) (3.2.2)\n",
            "Requirement already satisfied: imageio in /usr/local/lib/python3.7/dist-packages (from imgaug>=0.4.0->albumentations==0.4.6) (2.4.1)\n",
            "Requirement already satisfied: scikit-image>=0.14.2 in /usr/local/lib/python3.7/dist-packages (from imgaug>=0.4.0->albumentations==0.4.6) (0.18.3)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.7/dist-packages (from imgaug>=0.4.0->albumentations==0.4.6) (7.1.2)\n",
            "Requirement already satisfied: networkx>=2.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.14.2->imgaug>=0.4.0->albumentations==0.4.6) (2.6.3)\n",
            "Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.14.2->imgaug>=0.4.0->albumentations==0.4.6) (2021.11.2)\n",
            "Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.14.2->imgaug>=0.4.0->albumentations==0.4.6) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->imgaug>=0.4.0->albumentations==0.4.6) (0.11.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->imgaug>=0.4.0->albumentations==0.4.6) (1.3.2)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->imgaug>=0.4.0->albumentations==0.4.6) (2.8.2)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->imgaug>=0.4.0->albumentations==0.4.6) (3.0.7)\n",
            "Building wheels for collected packages: albumentations\n",
            "  Building wheel for albumentations (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for albumentations: filename=albumentations-0.4.6-py3-none-any.whl size=65174 sha256=25411a18a48d0c2a6c2147d935fa2a5300306a2a9af5411d1d0ed2387cd77e62\n",
            "  Stored in directory: /root/.cache/pip/wheels/cf/34/0f/cb2a5f93561a181a4bcc84847ad6aaceea8b5a3127469616cc\n",
            "Successfully built albumentations\n",
            "Installing collected packages: imgaug, albumentations\n",
            "  Attempting uninstall: imgaug\n",
            "    Found existing installation: imgaug 0.2.9\n",
            "    Uninstalling imgaug-0.2.9:\n",
            "      Successfully uninstalled imgaug-0.2.9\n",
            "  Attempting uninstall: albumentations\n",
            "    Found existing installation: albumentations 0.1.12\n",
            "    Uninstalling albumentations-0.1.12:\n",
            "      Successfully uninstalled albumentations-0.1.12\n",
            "Successfully installed albumentations-0.4.6 imgaug-0.4.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import glob\n",
        "from PIL import Image\n",
        "\n",
        "import torch\n",
        "from torch.utils.data.dataset import Dataset\n",
        "import torchvision.transforms.functional as TF\n",
        "import torchvision\n",
        "from torchvision import transforms\n",
        "\n",
        "import albumentations as albu\n",
        "from albumentations.pytorch import ToTensorV2\n",
        "from albumentations import OneOf,Compose\n",
        "\n",
        "class ClassifierDataset(Dataset):\n",
        "    def __init__(self, IMAGES_PATHS,label,Albumentation=False):\n",
        "      self.image_paths = IMAGES_PATHS\n",
        "      self.labels = label\n",
        "      self.albumentation = Albumentation\n",
        "\n",
        "      self.albu_transformations =  albu.Compose([\n",
        "          albu.Normalize(),\n",
        "          ToTensorV2(),\n",
        "          OneOf([albu.HorizontalFlip(),\n",
        "                  albu.VerticalFlip(),\n",
        "                  albu.RandomRotate90(),\n",
        "                  ],p=0.9)\n",
        "          #albu.ElasticTransform(alpha=1.1,alpha_affine=0.5,sigma=5,p=0.15),\n",
        "      ])\n",
        "      self.transformations = transforms.Compose([\n",
        "          #transforms.Grayscale(3),\n",
        "          transforms.ToTensor(),\n",
        "          transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])\n",
        "\n",
        "    def transform(self, image):\n",
        "      #Transform to tensor\n",
        "      if self.albumentation:\n",
        "          #It is always best to convert the make input to 3 dimensional for albumentation\n",
        "          augmented=  self.albu_transformations(image=image)\n",
        "          image = augmented['image']\n",
        "      else:\n",
        "          image = self.transformations(image)\n",
        "      image= image.type(torch.FloatTensor),\n",
        "      return image\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "      image = np.load(self.image_paths[index])\n",
        "      image = self.transform(image)\n",
        "      return image[0],self.labels[index]\n",
        "\n",
        "    def __len__(self):\n",
        "      return len(self.image_paths)\n"
      ],
      "metadata": {
        "id": "qp9j4wp3yfZC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **UTILS**"
      ],
      "metadata": {
        "id": "T-uvAL9qzJkd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import argparse\n",
        "import os\n",
        "\n",
        "def str2bool(v):\n",
        "    if v.lower() in ['true', 1]:\n",
        "        return True\n",
        "    elif v.lower() in ['false', 0]:\n",
        "        return False\n",
        "    else:\n",
        "        raise argparse.ArgumentTypeError('Boolean value expected.')\n",
        "\n",
        "def count_params(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "class AverageMeter(object):\n",
        "    \"\"\"Computes and stores the average and current value\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        self.reset()\n",
        "\n",
        "    def reset(self):\n",
        "        self.val = 0\n",
        "        self.avg = 0\n",
        "        self.sum = 0\n",
        "        self.count = 0\n",
        "\n",
        "    def update(self, val, n=1):\n",
        "        self.val = val\n",
        "        self.sum += val * n\n",
        "        self.count += n\n",
        "        self.avg = self.sum / self.count\n",
        "\n",
        "def load_directories(root_dir):\n",
        "    images_list = os.listdir(root_dir)\n",
        "    images_list.sort()\n",
        "    return [root_dir+ x for x in images_list]"
      ],
      "metadata": {
        "id": "f53nhPneygnV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **METRICS**"
      ],
      "metadata": {
        "id": "rMYqG9Luz_7Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "\n",
        "def Accuracy(output, label):\n",
        "  total = 0\n",
        "  correct =0\n",
        "  output_prob = (output>0.5).int()\n",
        "  correct += torch.sum(output_prob==label).item()\n",
        "  total += len(label)\n",
        "\n",
        "  return  correct / total\n",
        "\n",
        "def Confusion_matrix(output, label):\n",
        "  total = 0\n",
        "  smooth = 0.1\n",
        "\n",
        "  output_prob = (output>0.5).int()\n",
        "  label = label.int()\n",
        "\n",
        "  conf_matrix = torch.zeros(2, 2)\n",
        "  for t, p in zip(label, output_prob):\n",
        "      conf_matrix[t, p] += 1\n",
        "  TP = conf_matrix[1,1].item()\n",
        "  TN = conf_matrix[0,0].item()\n",
        "  FP = conf_matrix[0,1].item()\n",
        "  FN = conf_matrix[1,0].item()\n",
        "\n",
        "  total += len(label)\n",
        "  accuracy = (TP+TN)/total\n",
        "  sensitivity = TP / (TP+FN+ smooth)\n",
        "  specificity = TN / (TN+FP+ smooth)\n",
        "  \n",
        "  return  accuracy, sensitivity, specificity\n",
        "\n",
        "def Confusion_matrix2(output, label):\n",
        "  total = 0\n",
        "  smooth = 0.1\n",
        "\n",
        "  output_prob = (output>0.5).int()\n",
        "  label = label.int()\n",
        "\n",
        "  conf_matrix = torch.zeros(2, 2)\n",
        "  for t, p in zip(label, output_prob):\n",
        "      conf_matrix[t, p] += 1\n",
        "  TP = conf_matrix[1,1].item()\n",
        "  TN = conf_matrix[0,0].item()\n",
        "  FP = conf_matrix[0,1].item()\n",
        "  FN = conf_matrix[1,0].item()\n",
        "\n",
        "  return  TP,TN,FN,FP"
      ],
      "metadata": {
        "id": "8pg2Dvk6ygFC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **TRAIN CLASSIFIER**"
      ],
      "metadata": {
        "id": "kKrMHxgdEruG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install efficientnet_pytorch"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OErhhxaoReCl",
        "outputId": "af6f13b7-c8b8-4cda-cf28-787d0393e1ce"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting efficientnet_pytorch\n",
            "  Downloading efficientnet_pytorch-0.7.1.tar.gz (21 kB)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (from efficientnet_pytorch) (1.10.0+cu111)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch->efficientnet_pytorch) (3.10.0.2)\n",
            "Building wheels for collected packages: efficientnet-pytorch\n",
            "  Building wheel for efficientnet-pytorch (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for efficientnet-pytorch: filename=efficientnet_pytorch-0.7.1-py3-none-any.whl size=16446 sha256=3a634fedb9f3c5f7fa3b2bb46c9333b0626b2bc96cc88c99b894de0b2385eb74\n",
            "  Stored in directory: /root/.cache/pip/wheels/0e/cc/b2/49e74588263573ff778da58cc99b9c6349b496636a7e165be6\n",
            "Successfully built efficientnet-pytorch\n",
            "Installing collected packages: efficientnet-pytorch\n",
            "Successfully installed efficientnet-pytorch-0.7.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import argparse\n",
        "import os\n",
        "from collections import OrderedDict\n",
        "from glob import glob\n",
        "import pickle\n",
        "from tqdm import tqdm\n",
        "from sklearn.model_selection import train_test_split\n",
        "import yaml\n",
        "\n",
        "import torch\n",
        "import torch.backends.cudnn as cudnn\n",
        "import torchvision\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.optim import lr_scheduler\n",
        "\n",
        "from torchvision import datasets, models, transforms\n",
        "from PIL import Image\n",
        "from efficientnet_pytorch import EfficientNet"
      ],
      "metadata": {
        "id": "lHVDWAH5Ew0t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(train_loader,model,criterion,optimizer):\n",
        "    avg_meters = {'loss': AverageMeter(),\n",
        "                'accuracy': AverageMeter(),\n",
        "                'sensitivity':AverageMeter(),\n",
        "                'specificity': AverageMeter()}\n",
        "\n",
        "    model.train()\n",
        "    pbar = tqdm(total=len(train_loader))\n",
        "    for images, labels in train_loader:\n",
        "        images = images.cuda()\n",
        "        labels = labels.cuda()\n",
        "\n",
        "        outputs = model(images)\n",
        "        outputs = outputs.view(-1)\n",
        "        labels = labels.type_as(outputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        accuracy, sensitivity, specificity = Confusion_matrix(outputs,labels)\n",
        "        #print(loss)\n",
        "\n",
        "        # compute gradient and do optimizing step\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        avg_meters['loss'].update(loss.item(),images.size(0))\n",
        "        avg_meters['accuracy'].update(accuracy,images.size(0))\n",
        "        avg_meters['sensitivity'].update(sensitivity,images.size(0))\n",
        "        avg_meters['specificity'].update(specificity,images.size(0))\n",
        "\n",
        "        postfix = OrderedDict([\n",
        "            ('loss', avg_meters['loss'].avg),\n",
        "            ('accuracy', avg_meters['accuracy'].avg),\n",
        "            ('sensitivity', avg_meters['sensitivity'].avg),\n",
        "            ('specificity', avg_meters['specificity'].avg)\n",
        "        ])\n",
        "        pbar.set_postfix(postfix)\n",
        "        pbar.update(1)\n",
        "    pbar.close()\n",
        "\n",
        "    return OrderedDict([('loss', avg_meters['loss'].avg),\n",
        "                        ('accuracy', avg_meters['accuracy'].avg),\n",
        "                        ('sensitivity', avg_meters['sensitivity'].avg),\n",
        "                        ('specificity', avg_meters['specificity'].avg),])"
      ],
      "metadata": {
        "id": "WJY9FSgRSGcu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def validate(val_loader,model,criterion):\n",
        "    avg_meters = {'loss': AverageMeter(),\n",
        "                'accuracy': AverageMeter(),\n",
        "                'sensitivity':AverageMeter(),\n",
        "                'specificity': AverageMeter()}\n",
        "    model.eval()\n",
        "\n",
        "    pbar = tqdm(total=len(val_loader))\n",
        "    for images, labels in val_loader:\n",
        "        images = images.cuda()\n",
        "        labels = labels.cuda()\n",
        "\n",
        "        outputs = model(images)\n",
        "        outputs = outputs.view(-1)\n",
        "        labels = labels.type_as(outputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        accuracy, sensitivity, specificity = Confusion_matrix(outputs,labels)\n",
        "\n",
        "        avg_meters['loss'].update(loss.item(),images.size(0))\n",
        "        avg_meters['accuracy'].update(accuracy,images.size(0))\n",
        "        avg_meters['sensitivity'].update(sensitivity,images.size(0))\n",
        "        avg_meters['specificity'].update(specificity,images.size(0))\n",
        "\n",
        "        postfix = OrderedDict([\n",
        "            ('loss', avg_meters['loss'].avg),\n",
        "            ('accuracy', avg_meters['accuracy'].avg),\n",
        "            ('sensitivity', avg_meters['sensitivity'].avg),\n",
        "            ('specificity', avg_meters['specificity'].avg)\n",
        "        ])\n",
        "\n",
        "        pbar.set_postfix(postfix)\n",
        "        pbar.update(1)\n",
        "    pbar.close()\n",
        "\n",
        "    return OrderedDict([('loss', avg_meters['loss'].avg),\n",
        "                        ('accuracy', avg_meters['accuracy'].avg),\n",
        "                        ('sensitivity', avg_meters['sensitivity'].avg),\n",
        "                        ('specificity', avg_meters['specificity'].avg),])"
      ],
      "metadata": {
        "id": "lz6-T5doSiXt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Model Output directory\n",
        "OUTPUT_DIR = '/content/drive/MyDrive/data/Classification/model_output/'\n",
        "filename = 0\n",
        "epochs = 200\n",
        "batch_size = 24\n",
        "early_stopping = 30\n",
        "num_workers = 2\n",
        "optimizer = 'Adam'\n",
        "learning_rate = 1e-6\n",
        "momentum = 0.9\n",
        "weight_decay = 1e-4\n",
        "\n",
        "\n",
        "os.makedirs(OUTPUT_DIR+'efficientnetb{}'.format(filename),exist_ok=True)\n",
        "print('Made directory called efficientnetb{}'.format(filename))\n",
        "\n",
        "print('-' * 20)\n",
        "\n",
        "#save configuration\n",
        "# with open(OUTPUT_DIR+'efficientnetb{}/config.yml'.format(filename), 'w') as f:\n",
        "#     yaml.dump(config, f)\n",
        "\n",
        "# Data directory\n",
        "TRAIN_DIR = '/content/drive/MyDrive/data/Efficient_net/train/'\n",
        "VAL_DIR = '/content/drive/MyDrive/data/Efficient_net/val/'\n",
        "CLEAN_TRAIN_DIR ='/content/drive/MyDrive/data/Efficient_net/clean_train/'\n",
        "CLEAN_VAL_DIR = '/content/drive/MyDrive/data/Efficient_net/clean_val/'\n",
        "LABEL_DIR = '/content/drive/MyDrive/data/Efficient_net/label/'\n",
        "\n",
        "with open(LABEL_DIR+'train.txt','rb') as fp:\n",
        "  train_label = pickle.load(fp)\n",
        "with open(LABEL_DIR+'val.txt','rb') as fp:\n",
        "  val_label = pickle.load(fp)\n",
        "with open(LABEL_DIR+'clean_train.txt','rb') as fp:\n",
        "  clean_train_label = pickle.load(fp)\n",
        "with open(LABEL_DIR+'clean_val.txt','rb') as fp:\n",
        "  clean_val_label = pickle.load(fp)\n",
        "\n",
        "# Get image files path as list\n",
        "train_image_paths = load_directories(TRAIN_DIR)\n",
        "val_image_paths = load_directories(VAL_DIR)\n",
        "clean_train_images_paths = load_directories(CLEAN_TRAIN_DIR)\n",
        "clean_val_images_paths = load_directories(CLEAN_VAL_DIR)\n",
        "\n",
        "train_image_paths.extend(clean_train_images_paths)\n",
        "val_image_paths.extend(clean_val_images_paths)\n",
        "train_label.extend(clean_train_label)\n",
        "val_label.extend(clean_val_label)\n",
        "\n",
        "print(\"=\"*50)\n",
        "print(\"The length of image are train: {} validation: {}\".format(len(train_image_paths),len(val_image_paths)))\n",
        "\n",
        "print(\"============================TRAINING===========================================\")\n",
        "print(\"Cancer nodules:{} Non Cancer nodules:{}\".format(np.sum(train_label),len(train_label)-np.sum(train_label)))\n",
        "print(\"Ratio is {:4f}\".format(np.sum(train_label)/(len(train_label)-np.sum(train_label))))\n",
        "print(\"============================VALIDATION=========================================\")\n",
        "print(\"Cancer nodules:{} Non Cancer nodules:{}\".format(np.sum(val_label),len(val_label)-np.sum(val_label)))\n",
        "print(\"Ratio is {:4f}\".format(np.sum(val_label)/(len(val_label)-np.sum(val_label))))\n",
        "# Create Dataset\n",
        "train_dataset = ClassifierDataset(train_image_paths,train_label)\n",
        "val_dataset = ClassifierDataset(val_image_paths,val_label)\n",
        "\n",
        "# Model\n",
        "cudnn.benchmark = True\n",
        "model = EfficientNet.from_pretrained('efficientnet-b{}'.format(filename))\n",
        "\n",
        "#Fine tuning top layers\n",
        "num_ftrs = model._fc.in_features\n",
        "model._fc = nn.Sequential(nn.Linear(num_ftrs,1),\n",
        "                            nn.Sigmoid())\n",
        "\n",
        "criterion = nn.BCEWithLogitsLoss().cuda()\n",
        "\n",
        "\n",
        "if torch.cuda.device_count() > 1:\n",
        "    print(\"Let's use\", torch.cuda.device_count(), \"GPUs!\")\n",
        "    model = nn.DataParallel(model)\n",
        "model = model.cuda()\n",
        "params = filter(lambda p: p.requires_grad, model.parameters())\n",
        "optimizer = optim.Adam(params, lr=learning_rate, weight_decay=weight_decay)\n",
        "\n",
        "#if config['optimizer'] == 'Adam':\n",
        "#elif config['optimizer'] == 'SGD':\n",
        "#    optimizer = optim.SGD(params, lr=config['lr'], momentum=config['momentum'],nesterov=config['nesterov'], weight_decay=config['weight_decay'])\n",
        "#exp_lr_scheduler = lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)\n",
        "# Create Dataloader\n",
        "train_loader = torch.utils.data.DataLoader(\n",
        "    train_dataset,\n",
        "    batch_size=batch_size,\n",
        "    shuffle=True,\n",
        "    pin_memory=True,\n",
        "    drop_last=True,\n",
        "    num_workers=6)\n",
        "val_loader = torch.utils.data.DataLoader(\n",
        "    val_dataset,\n",
        "    batch_size=batch_size,\n",
        "    shuffle=False,\n",
        "    pin_memory=True,\n",
        "    drop_last=False,\n",
        "    num_workers=6)\n",
        "\n",
        "log= pd.DataFrame(index=[],columns= ['epoch', 'loss', 'accuracy','sensitivity','specificity,',\n",
        "                                    'val_loss', 'val_accuracy','val_sensitivity','val_specificity'])\n",
        "\n",
        "best_loss= 10\n",
        "trigger = 0\n",
        "\n",
        "for epoch in range(epochs):\n",
        "\n",
        "    # train for one epoch\n",
        "    train_log = train(train_loader, model, criterion, optimizer)\n",
        "    # evaluate on validation set\n",
        "    val_log = validate(val_loader, model, criterion)\n",
        "\n",
        "    print('Training epoch [{}/{}], Training BCE loss:{:.4f}, Training accuracy:{:.4f}, Training sensitivity:{:.4f}, Training specificity:{:.4f}, \\\n",
        "                Validation BCE loss:{:.4f}, Validation accuracy:{:.4f}, Validation sensitivity:{:.4f}, Validation specificity:{:.4f},'.format( \n",
        "        epoch + 1, epochs, train_log['loss'], train_log['accuracy'], train_log['sensitivity'], train_log['specificity'],val_log['loss'], val_log['accuracy'],val_log['sensitivity'], val_log['specificity']))\n",
        "\n",
        "    tmp = pd.Series([\n",
        "        epoch,\n",
        "        train_log['loss'],\n",
        "        train_log['accuracy'],\n",
        "        train_log['sensitivity'],\n",
        "        train_log['specificity'],\n",
        "        val_log['loss'],\n",
        "        val_log['accuracy'],\n",
        "        val_log['sensitivity'],\n",
        "        val_log['specificity'],\n",
        "    ], index=['epoch', 'loss', 'accuracy','sensitivity','specificity,','val_loss', 'val_accuracy','val_sensitivity','val_specificity'])\n",
        "\n",
        "    log = log.append(tmp, ignore_index=True)\n",
        "    log.to_csv(OUTPUT_DIR+'efficientnetb{}/log.csv'.format(filename), index=False)\n",
        "\n",
        "    trigger += 1\n",
        "\n",
        "    if val_log['loss'] < best_loss:\n",
        "        torch.save(model.state_dict(), OUTPUT_DIR+'efficientnetb{}/model.pth'.format(filename))\n",
        "        best_loss= val_log['loss']\n",
        "        print(\"=> saved best model as validation loss is greater than previous best loss\")\n",
        "        trigger = 0\n",
        "\n",
        "    # early stopping\n",
        "    if early_stopping >= 0 and trigger >= early_stopping:\n",
        "        print(\"=> early stopping\")\n",
        "        break\n",
        "\n",
        "    torch.cuda.empty_cache()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "8510774b14a04271a3d9e3de2b32621b",
            "8d7b4622d4574f168acfd897247d2b81",
            "64ae4e2cbfcb453989d0d654486981da",
            "c82312afbe454f4eb4f9ef99529b6837",
            "6ce29191407a487a92dfc9b7f3760a53",
            "2c347dd9b89f4d2fbae149c2f86e476a",
            "1d0d201e16824bd38f71fb01545ea097",
            "7983daaf4ff44473be2c0ab6c4e6962f",
            "f21a4341fc924eb69603c26582e115fc",
            "35f0354d06cc4149b6776c0597857178",
            "97faa256ee22473dbd2860075c7c83f1"
          ]
        },
        "id": "XXuSwE6mUd-Y",
        "outputId": "e52608bb-90ed-4416-f3f8-ea6b198744ba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Made directory called efficientnetb0\n",
            "--------------------\n",
            "==================================================\n",
            "The length of image are train: 5920 validation: 2042\n",
            "============================TRAINING===========================================\n",
            "Cancer nodules:3146 Non Cancer nodules:2774\n",
            "Ratio is 1.134102\n",
            "============================VALIDATION=========================================\n",
            "Cancer nodules:914 Non Cancer nodules:1128\n",
            "Ratio is 0.810284\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://github.com/lukemelas/EfficientNet-PyTorch/releases/download/1.0/efficientnet-b0-355c32eb.pth\" to /root/.cache/torch/hub/checkpoints/efficientnet-b0-355c32eb.pth\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0.00/20.4M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8510774b14a04271a3d9e3de2b32621b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded pretrained weights for efficientnet-b0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 246/246 [05:46<00:00,  1.41s/it, loss=0.708, accuracy=0.494, sensitivity=0.401, specificity=0.594]\n",
            "100%|██████████| 86/86 [02:24<00:00,  1.67s/it, loss=0.744, accuracy=0.579, sensitivity=0.239, specificity=0.624]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training epoch [1/200], Training BCE loss:0.7076, Training accuracy:0.4942, Training sensitivity:0.4011, Training specificity:0.5943,                 Validation BCE loss:0.7444, Validation accuracy:0.5793, Validation sensitivity:0.2392, Validation specificity:0.6236,\n",
            "=> saved best model as validation loss is greater than previous best loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 246/246 [01:23<00:00,  2.96it/s, loss=0.705, accuracy=0.54, sensitivity=0.413, specificity=0.679]\n",
            "100%|██████████| 86/86 [00:08<00:00, 10.42it/s, loss=0.743, accuracy=0.626, sensitivity=0.294, specificity=0.628]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training epoch [2/200], Training BCE loss:0.7048, Training accuracy:0.5403, Training sensitivity:0.4128, Training specificity:0.6793,                 Validation BCE loss:0.7426, Validation accuracy:0.6259, Validation sensitivity:0.2936, Validation specificity:0.6279,\n",
            "=> saved best model as validation loss is greater than previous best loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 246/246 [00:32<00:00,  7.53it/s, loss=0.702, accuracy=0.585, sensitivity=0.431, specificity=0.753]\n",
            "100%|██████████| 86/86 [00:08<00:00, 10.68it/s, loss=0.74, accuracy=0.644, sensitivity=0.296, specificity=0.643]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training epoch [3/200], Training BCE loss:0.7019, Training accuracy:0.5849, Training sensitivity:0.4309, Training specificity:0.7534,                 Validation BCE loss:0.7401, Validation accuracy:0.6440, Validation sensitivity:0.2958, Validation specificity:0.6429,\n",
            "=> saved best model as validation loss is greater than previous best loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 246/246 [00:32<00:00,  7.51it/s, loss=0.699, accuracy=0.612, sensitivity=0.457, specificity=0.785]\n",
            "100%|██████████| 86/86 [00:40<00:00,  2.13it/s, loss=0.737, accuracy=0.656, sensitivity=0.301, specificity=0.648]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training epoch [4/200], Training BCE loss:0.6991, Training accuracy:0.6123, Training sensitivity:0.4565, Training specificity:0.7852,                 Validation BCE loss:0.7371, Validation accuracy:0.6557, Validation sensitivity:0.3007, Validation specificity:0.6480,\n",
            "=> saved best model as validation loss is greater than previous best loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 246/246 [00:32<00:00,  7.52it/s, loss=0.696, accuracy=0.62, sensitivity=0.458, specificity=0.805]\n",
            "100%|██████████| 86/86 [00:23<00:00,  3.70it/s, loss=0.734, accuracy=0.665, sensitivity=0.308, specificity=0.65]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training epoch [5/200], Training BCE loss:0.6964, Training accuracy:0.6204, Training sensitivity:0.4577, Training specificity:0.8053,                 Validation BCE loss:0.7340, Validation accuracy:0.6645, Validation sensitivity:0.3085, Validation specificity:0.6495,\n",
            "=> saved best model as validation loss is greater than previous best loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 246/246 [00:32<00:00,  7.49it/s, loss=0.693, accuracy=0.631, sensitivity=0.473, specificity=0.81]\n",
            "100%|██████████| 86/86 [00:07<00:00, 11.81it/s, loss=0.73, accuracy=0.669, sensitivity=0.307, specificity=0.657]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training epoch [6/200], Training BCE loss:0.6929, Training accuracy:0.6309, Training sensitivity:0.4726, Training specificity:0.8101,                 Validation BCE loss:0.7303, Validation accuracy:0.6690, Validation sensitivity:0.3069, Validation specificity:0.6573,\n",
            "=> saved best model as validation loss is greater than previous best loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 246/246 [00:32<00:00,  7.55it/s, loss=0.689, accuracy=0.648, sensitivity=0.5, specificity=0.82]\n",
            "100%|██████████| 86/86 [00:06<00:00, 13.08it/s, loss=0.726, accuracy=0.668, sensitivity=0.296, specificity=0.661]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training epoch [7/200], Training BCE loss:0.6891, Training accuracy:0.6480, Training sensitivity:0.5003, Training specificity:0.8205,                 Validation BCE loss:0.7264, Validation accuracy:0.6680, Validation sensitivity:0.2963, Validation specificity:0.6612,\n",
            "=> saved best model as validation loss is greater than previous best loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 246/246 [00:32<00:00,  7.53it/s, loss=0.685, accuracy=0.651, sensitivity=0.506, specificity=0.823]\n",
            "100%|██████████| 86/86 [00:05<00:00, 15.25it/s, loss=0.723, accuracy=0.665, sensitivity=0.3, specificity=0.651]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training epoch [8/200], Training BCE loss:0.6855, Training accuracy:0.6513, Training sensitivity:0.5055, Training specificity:0.8231,                 Validation BCE loss:0.7226, Validation accuracy:0.6650, Validation sensitivity:0.2996, Validation specificity:0.6511,\n",
            "=> saved best model as validation loss is greater than previous best loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 246/246 [00:32<00:00,  7.63it/s, loss=0.681, accuracy=0.66, sensitivity=0.537, specificity=0.808]\n",
            "100%|██████████| 86/86 [00:05<00:00, 15.16it/s, loss=0.719, accuracy=0.668, sensitivity=0.311, specificity=0.64]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training epoch [9/200], Training BCE loss:0.6815, Training accuracy:0.6604, Training sensitivity:0.5365, Training specificity:0.8076,                 Validation BCE loss:0.7187, Validation accuracy:0.6685, Validation sensitivity:0.3108, Validation specificity:0.6398,\n",
            "=> saved best model as validation loss is greater than previous best loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 246/246 [00:32<00:00,  7.64it/s, loss=0.678, accuracy=0.667, sensitivity=0.553, specificity=0.802]\n",
            "100%|██████████| 86/86 [00:05<00:00, 15.26it/s, loss=0.715, accuracy=0.672, sensitivity=0.322, specificity=0.638]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training epoch [10/200], Training BCE loss:0.6778, Training accuracy:0.6667, Training sensitivity:0.5527, Training specificity:0.8017,                 Validation BCE loss:0.7148, Validation accuracy:0.6724, Validation sensitivity:0.3223, Validation specificity:0.6376,\n",
            "=> saved best model as validation loss is greater than previous best loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 246/246 [00:32<00:00,  7.68it/s, loss=0.673, accuracy=0.688, sensitivity=0.59, specificity=0.807]\n",
            "100%|██████████| 86/86 [00:05<00:00, 14.62it/s, loss=0.711, accuracy=0.673, sensitivity=0.33, specificity=0.629]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training epoch [11/200], Training BCE loss:0.6731, Training accuracy:0.6878, Training sensitivity:0.5898, Training specificity:0.8070,                 Validation BCE loss:0.7112, Validation accuracy:0.6734, Validation sensitivity:0.3300, Validation specificity:0.6292,\n",
            "=> saved best model as validation loss is greater than previous best loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 246/246 [00:31<00:00,  7.71it/s, loss=0.67, accuracy=0.69, sensitivity=0.601, specificity=0.805]\n",
            "100%|██████████| 86/86 [00:05<00:00, 14.90it/s, loss=0.708, accuracy=0.678, sensitivity=0.347, specificity=0.617]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training epoch [12/200], Training BCE loss:0.6702, Training accuracy:0.6904, Training sensitivity:0.6009, Training specificity:0.8047,                 Validation BCE loss:0.7080, Validation accuracy:0.6783, Validation sensitivity:0.3466, Validation specificity:0.6173,\n",
            "=> saved best model as validation loss is greater than previous best loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 246/246 [00:31<00:00,  7.73it/s, loss=0.667, accuracy=0.698, sensitivity=0.623, specificity=0.795]\n",
            "100%|██████████| 86/86 [00:05<00:00, 15.01it/s, loss=0.705, accuracy=0.679, sensitivity=0.344, specificity=0.617]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training epoch [13/200], Training BCE loss:0.6668, Training accuracy:0.6978, Training sensitivity:0.6231, Training specificity:0.7945,                 Validation BCE loss:0.7045, Validation accuracy:0.6792, Validation sensitivity:0.3441, Validation specificity:0.6173,\n",
            "=> saved best model as validation loss is greater than previous best loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 246/246 [00:31<00:00,  7.72it/s, loss=0.664, accuracy=0.701, sensitivity=0.634, specificity=0.788]\n",
            "100%|██████████| 86/86 [00:05<00:00, 14.84it/s, loss=0.702, accuracy=0.682, sensitivity=0.348, specificity=0.617]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training epoch [14/200], Training BCE loss:0.6635, Training accuracy:0.7009, Training sensitivity:0.6335, Training specificity:0.7882,                 Validation BCE loss:0.7019, Validation accuracy:0.6822, Validation sensitivity:0.3484, Validation specificity:0.6173,\n",
            "=> saved best model as validation loss is greater than previous best loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 246/246 [00:31<00:00,  7.71it/s, loss=0.661, accuracy=0.708, sensitivity=0.652, specificity=0.78]\n",
            "100%|██████████| 86/86 [00:05<00:00, 15.07it/s, loss=0.699, accuracy=0.69, sensitivity=0.36, specificity=0.617]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training epoch [15/200], Training BCE loss:0.6606, Training accuracy:0.7083, Training sensitivity:0.6518, Training specificity:0.7802,                 Validation BCE loss:0.6990, Validation accuracy:0.6900, Validation sensitivity:0.3596, Validation specificity:0.6171,\n",
            "=> saved best model as validation loss is greater than previous best loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 246/246 [00:31<00:00,  7.73it/s, loss=0.658, accuracy=0.711, sensitivity=0.657, specificity=0.783]\n",
            "100%|██████████| 86/86 [00:05<00:00, 15.04it/s, loss=0.696, accuracy=0.69, sensitivity=0.364, specificity=0.615]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training epoch [16/200], Training BCE loss:0.6580, Training accuracy:0.7110, Training sensitivity:0.6570, Training specificity:0.7833,                 Validation BCE loss:0.6965, Validation accuracy:0.6905, Validation sensitivity:0.3639, Validation specificity:0.6153,\n",
            "=> saved best model as validation loss is greater than previous best loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 246/246 [00:31<00:00,  7.74it/s, loss=0.654, accuracy=0.721, sensitivity=0.671, specificity=0.784]\n",
            "100%|██████████| 86/86 [00:05<00:00, 15.10it/s, loss=0.694, accuracy=0.694, sensitivity=0.361, specificity=0.62]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training epoch [17/200], Training BCE loss:0.6543, Training accuracy:0.7205, Training sensitivity:0.6713, Training specificity:0.7835,                 Validation BCE loss:0.6939, Validation accuracy:0.6939, Validation sensitivity:0.3612, Validation specificity:0.6202,\n",
            "=> saved best model as validation loss is greater than previous best loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 246/246 [00:31<00:00,  7.71it/s, loss=0.652, accuracy=0.717, sensitivity=0.67, specificity=0.781]\n",
            "100%|██████████| 86/86 [00:05<00:00, 15.08it/s, loss=0.691, accuracy=0.696, sensitivity=0.362, specificity=0.62]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training epoch [18/200], Training BCE loss:0.6519, Training accuracy:0.7168, Training sensitivity:0.6700, Training specificity:0.7806,                 Validation BCE loss:0.6912, Validation accuracy:0.6959, Validation sensitivity:0.3622, Validation specificity:0.6202,\n",
            "=> saved best model as validation loss is greater than previous best loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 246/246 [00:31<00:00,  7.70it/s, loss=0.65, accuracy=0.716, sensitivity=0.677, specificity=0.77]\n",
            "100%|██████████| 86/86 [00:05<00:00, 15.00it/s, loss=0.689, accuracy=0.698, sensitivity=0.364, specificity=0.627]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training epoch [19/200], Training BCE loss:0.6496, Training accuracy:0.7165, Training sensitivity:0.6769, Training specificity:0.7701,                 Validation BCE loss:0.6886, Validation accuracy:0.6983, Validation sensitivity:0.3639, Validation specificity:0.6271,\n",
            "=> saved best model as validation loss is greater than previous best loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 246/246 [00:31<00:00,  7.71it/s, loss=0.647, accuracy=0.729, sensitivity=0.689, specificity=0.783]\n",
            "100%|██████████| 86/86 [00:06<00:00, 14.28it/s, loss=0.687, accuracy=0.7, sensitivity=0.373, specificity=0.617]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training epoch [20/200], Training BCE loss:0.6468, Training accuracy:0.7290, Training sensitivity:0.6890, Training specificity:0.7827,                 Validation BCE loss:0.6870, Validation accuracy:0.6998, Validation sensitivity:0.3733, Validation specificity:0.6171,\n",
            "=> saved best model as validation loss is greater than previous best loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 246/246 [00:31<00:00,  7.74it/s, loss=0.645, accuracy=0.728, sensitivity=0.691, specificity=0.783]\n",
            "100%|██████████| 86/86 [00:05<00:00, 15.10it/s, loss=0.686, accuracy=0.701, sensitivity=0.377, specificity=0.614]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training epoch [21/200], Training BCE loss:0.6451, Training accuracy:0.7278, Training sensitivity:0.6913, Training specificity:0.7829,                 Validation BCE loss:0.6856, Validation accuracy:0.7013, Validation sensitivity:0.3775, Validation specificity:0.6142,\n",
            "=> saved best model as validation loss is greater than previous best loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 246/246 [00:31<00:00,  7.73it/s, loss=0.643, accuracy=0.736, sensitivity=0.698, specificity=0.789]\n",
            "100%|██████████| 86/86 [00:05<00:00, 15.05it/s, loss=0.683, accuracy=0.703, sensitivity=0.374, specificity=0.619]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training epoch [22/200], Training BCE loss:0.6427, Training accuracy:0.7358, Training sensitivity:0.6980, Training specificity:0.7885,                 Validation BCE loss:0.6831, Validation accuracy:0.7032, Validation sensitivity:0.3745, Validation specificity:0.6194,\n",
            "=> saved best model as validation loss is greater than previous best loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 246/246 [00:32<00:00,  7.68it/s, loss=0.639, accuracy=0.738, sensitivity=0.697, specificity=0.79]\n",
            "100%|██████████| 86/86 [00:05<00:00, 14.99it/s, loss=0.681, accuracy=0.703, sensitivity=0.376, specificity=0.618]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training epoch [23/200], Training BCE loss:0.6394, Training accuracy:0.7376, Training sensitivity:0.6971, Training specificity:0.7897,                 Validation BCE loss:0.6814, Validation accuracy:0.7032, Validation sensitivity:0.3756, Validation specificity:0.6184,\n",
            "=> saved best model as validation loss is greater than previous best loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 246/246 [00:31<00:00,  7.73it/s, loss=0.638, accuracy=0.739, sensitivity=0.709, specificity=0.777]\n",
            "100%|██████████| 86/86 [00:05<00:00, 15.10it/s, loss=0.679, accuracy=0.706, sensitivity=0.374, specificity=0.626]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training epoch [24/200], Training BCE loss:0.6380, Training accuracy:0.7387, Training sensitivity:0.7090, Training specificity:0.7772,                 Validation BCE loss:0.6794, Validation accuracy:0.7062, Validation sensitivity:0.3738, Validation specificity:0.6265,\n",
            "=> saved best model as validation loss is greater than previous best loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 246/246 [00:31<00:00,  7.73it/s, loss=0.635, accuracy=0.745, sensitivity=0.711, specificity=0.792]\n",
            "100%|██████████| 86/86 [00:05<00:00, 15.14it/s, loss=0.678, accuracy=0.707, sensitivity=0.373, specificity=0.627]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training epoch [25/200], Training BCE loss:0.6353, Training accuracy:0.7447, Training sensitivity:0.7107, Training specificity:0.7918,                 Validation BCE loss:0.6775, Validation accuracy:0.7067, Validation sensitivity:0.3732, Validation specificity:0.6275,\n",
            "=> saved best model as validation loss is greater than previous best loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 246/246 [00:31<00:00,  7.73it/s, loss=0.633, accuracy=0.746, sensitivity=0.711, specificity=0.791]\n",
            "100%|██████████| 86/86 [00:05<00:00, 15.11it/s, loss=0.676, accuracy=0.71, sensitivity=0.377, specificity=0.628]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training epoch [26/200], Training BCE loss:0.6327, Training accuracy:0.7456, Training sensitivity:0.7107, Training specificity:0.7906,                 Validation BCE loss:0.6764, Validation accuracy:0.7101, Validation sensitivity:0.3774, Validation specificity:0.6282,\n",
            "=> saved best model as validation loss is greater than previous best loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 246/246 [00:31<00:00,  7.72it/s, loss=0.632, accuracy=0.747, sensitivity=0.722, specificity=0.782]\n",
            "100%|██████████| 86/86 [00:05<00:00, 14.90it/s, loss=0.674, accuracy=0.71, sensitivity=0.371, specificity=0.638]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training epoch [27/200], Training BCE loss:0.6320, Training accuracy:0.7471, Training sensitivity:0.7223, Training specificity:0.7820,                 Validation BCE loss:0.6744, Validation accuracy:0.7101, Validation sensitivity:0.3708, Validation specificity:0.6380,\n",
            "=> saved best model as validation loss is greater than previous best loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 246/246 [00:31<00:00,  7.72it/s, loss=0.63, accuracy=0.751, sensitivity=0.716, specificity=0.795]\n",
            "100%|██████████| 86/86 [00:05<00:00, 15.21it/s, loss=0.673, accuracy=0.712, sensitivity=0.375, specificity=0.636]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training epoch [28/200], Training BCE loss:0.6297, Training accuracy:0.7505, Training sensitivity:0.7157, Training specificity:0.7951,                 Validation BCE loss:0.6732, Validation accuracy:0.7116, Validation sensitivity:0.3747, Validation specificity:0.6360,\n",
            "=> saved best model as validation loss is greater than previous best loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 246/246 [00:31<00:00,  7.73it/s, loss=0.627, accuracy=0.753, sensitivity=0.719, specificity=0.8]\n",
            "100%|██████████| 86/86 [00:05<00:00, 14.76it/s, loss=0.672, accuracy=0.714, sensitivity=0.374, specificity=0.639]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training epoch [29/200], Training BCE loss:0.6273, Training accuracy:0.7532, Training sensitivity:0.7187, Training specificity:0.7997,                 Validation BCE loss:0.6715, Validation accuracy:0.7140, Validation sensitivity:0.3742, Validation specificity:0.6394,\n",
            "=> saved best model as validation loss is greater than previous best loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 246/246 [00:31<00:00,  7.69it/s, loss=0.625, accuracy=0.754, sensitivity=0.724, specificity=0.794]\n",
            "100%|██████████| 86/86 [00:05<00:00, 15.02it/s, loss=0.67, accuracy=0.715, sensitivity=0.375, specificity=0.641]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training epoch [30/200], Training BCE loss:0.6251, Training accuracy:0.7541, Training sensitivity:0.7238, Training specificity:0.7939,                 Validation BCE loss:0.6703, Validation accuracy:0.7155, Validation sensitivity:0.3749, Validation specificity:0.6407,\n",
            "=> saved best model as validation loss is greater than previous best loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 246/246 [00:32<00:00,  7.68it/s, loss=0.625, accuracy=0.756, sensitivity=0.728, specificity=0.799]\n",
            "100%|██████████| 86/86 [00:05<00:00, 14.93it/s, loss=0.669, accuracy=0.714, sensitivity=0.375, specificity=0.638]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training epoch [31/200], Training BCE loss:0.6253, Training accuracy:0.7558, Training sensitivity:0.7281, Training specificity:0.7993,                 Validation BCE loss:0.6692, Validation accuracy:0.7135, Validation sensitivity:0.3748, Validation specificity:0.6377,\n",
            "=> saved best model as validation loss is greater than previous best loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 246/246 [00:31<00:00,  7.72it/s, loss=0.622, accuracy=0.758, sensitivity=0.725, specificity=0.803]\n",
            "100%|██████████| 86/86 [00:05<00:00, 15.03it/s, loss=0.668, accuracy=0.717, sensitivity=0.382, specificity=0.635]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training epoch [32/200], Training BCE loss:0.6223, Training accuracy:0.7580, Training sensitivity:0.7252, Training specificity:0.8035,                 Validation BCE loss:0.6685, Validation accuracy:0.7169, Validation sensitivity:0.3820, Validation specificity:0.6348,\n",
            "=> saved best model as validation loss is greater than previous best loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 246/246 [00:31<00:00,  7.73it/s, loss=0.62, accuracy=0.76, sensitivity=0.729, specificity=0.805]\n",
            "100%|██████████| 86/86 [00:05<00:00, 15.00it/s, loss=0.667, accuracy=0.718, sensitivity=0.377, specificity=0.646]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training epoch [33/200], Training BCE loss:0.6204, Training accuracy:0.7600, Training sensitivity:0.7290, Training specificity:0.8048,                 Validation BCE loss:0.6668, Validation accuracy:0.7184, Validation sensitivity:0.3765, Validation specificity:0.6461,\n",
            "=> saved best model as validation loss is greater than previous best loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 246/246 [00:31<00:00,  7.72it/s, loss=0.619, accuracy=0.763, sensitivity=0.732, specificity=0.806]\n",
            "100%|██████████| 86/86 [00:05<00:00, 14.68it/s, loss=0.666, accuracy=0.72, sensitivity=0.376, specificity=0.653]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training epoch [34/200], Training BCE loss:0.6190, Training accuracy:0.7627, Training sensitivity:0.7315, Training specificity:0.8062,                 Validation BCE loss:0.6657, Validation accuracy:0.7204, Validation sensitivity:0.3763, Validation specificity:0.6528,\n",
            "=> saved best model as validation loss is greater than previous best loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 246/246 [00:31<00:00,  7.69it/s, loss=0.616, accuracy=0.77, sensitivity=0.738, specificity=0.813]\n",
            "100%|██████████| 86/86 [00:05<00:00, 14.90it/s, loss=0.664, accuracy=0.72, sensitivity=0.38, specificity=0.651]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training epoch [35/200], Training BCE loss:0.6159, Training accuracy:0.7703, Training sensitivity:0.7377, Training specificity:0.8129,                 Validation BCE loss:0.6644, Validation accuracy:0.7204, Validation sensitivity:0.3805, Validation specificity:0.6512,\n",
            "=> saved best model as validation loss is greater than previous best loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 246/246 [00:32<00:00,  7.68it/s, loss=0.614, accuracy=0.774, sensitivity=0.744, specificity=0.815]\n",
            "100%|██████████| 86/86 [00:05<00:00, 14.50it/s, loss=0.664, accuracy=0.721, sensitivity=0.385, specificity=0.647]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training epoch [36/200], Training BCE loss:0.6144, Training accuracy:0.7735, Training sensitivity:0.7435, Training specificity:0.8149,                 Validation BCE loss:0.6639, Validation accuracy:0.7214, Validation sensitivity:0.3847, Validation specificity:0.6469,\n",
            "=> saved best model as validation loss is greater than previous best loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 246/246 [00:32<00:00,  7.69it/s, loss=0.615, accuracy=0.768, sensitivity=0.739, specificity=0.812]\n",
            "100%|██████████| 86/86 [00:05<00:00, 14.99it/s, loss=0.663, accuracy=0.721, sensitivity=0.384, specificity=0.647]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training epoch [37/200], Training BCE loss:0.6149, Training accuracy:0.7683, Training sensitivity:0.7385, Training specificity:0.8124,                 Validation BCE loss:0.6630, Validation accuracy:0.7214, Validation sensitivity:0.3839, Validation specificity:0.6473,\n",
            "=> saved best model as validation loss is greater than previous best loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 246/246 [00:31<00:00,  7.73it/s, loss=0.611, accuracy=0.778, sensitivity=0.748, specificity=0.82]\n",
            "100%|██████████| 86/86 [00:05<00:00, 15.09it/s, loss=0.662, accuracy=0.725, sensitivity=0.393, specificity=0.647]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training epoch [38/200], Training BCE loss:0.6106, Training accuracy:0.7778, Training sensitivity:0.7484, Training specificity:0.8196,                 Validation BCE loss:0.6624, Validation accuracy:0.7248, Validation sensitivity:0.3929, Validation specificity:0.6474,\n",
            "=> saved best model as validation loss is greater than previous best loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 246/246 [00:32<00:00,  7.62it/s, loss=0.609, accuracy=0.78, sensitivity=0.745, specificity=0.826]\n",
            "100%|██████████| 86/86 [00:05<00:00, 14.83it/s, loss=0.661, accuracy=0.722, sensitivity=0.386, specificity=0.651]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training epoch [39/200], Training BCE loss:0.6093, Training accuracy:0.7796, Training sensitivity:0.7453, Training specificity:0.8262,                 Validation BCE loss:0.6613, Validation accuracy:0.7223, Validation sensitivity:0.3865, Validation specificity:0.6507,\n",
            "=> saved best model as validation loss is greater than previous best loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 246/246 [00:31<00:00,  7.72it/s, loss=0.609, accuracy=0.775, sensitivity=0.746, specificity=0.816]\n",
            "100%|██████████| 86/86 [00:05<00:00, 14.97it/s, loss=0.661, accuracy=0.727, sensitivity=0.393, specificity=0.649]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training epoch [40/200], Training BCE loss:0.6093, Training accuracy:0.7752, Training sensitivity:0.7459, Training specificity:0.8159,                 Validation BCE loss:0.6605, Validation accuracy:0.7267, Validation sensitivity:0.3932, Validation specificity:0.6492,\n",
            "=> saved best model as validation loss is greater than previous best loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 246/246 [00:31<00:00,  7.73it/s, loss=0.606, accuracy=0.787, sensitivity=0.752, specificity=0.83]\n",
            "100%|██████████| 86/86 [00:05<00:00, 15.00it/s, loss=0.66, accuracy=0.728, sensitivity=0.393, specificity=0.652]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training epoch [41/200], Training BCE loss:0.6063, Training accuracy:0.7868, Training sensitivity:0.7522, Training specificity:0.8305,                 Validation BCE loss:0.6599, Validation accuracy:0.7277, Validation sensitivity:0.3929, Validation specificity:0.6524,\n",
            "=> saved best model as validation loss is greater than previous best loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 246/246 [00:31<00:00,  7.72it/s, loss=0.606, accuracy=0.787, sensitivity=0.757, specificity=0.827]\n",
            "100%|██████████| 86/86 [00:05<00:00, 15.14it/s, loss=0.659, accuracy=0.728, sensitivity=0.393, specificity=0.652]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training epoch [42/200], Training BCE loss:0.6057, Training accuracy:0.7868, Training sensitivity:0.7572, Training specificity:0.8271,                 Validation BCE loss:0.6592, Validation accuracy:0.7277, Validation sensitivity:0.3934, Validation specificity:0.6516,\n",
            "=> saved best model as validation loss is greater than previous best loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 246/246 [00:31<00:00,  7.73it/s, loss=0.604, accuracy=0.789, sensitivity=0.757, specificity=0.835]\n",
            "100%|██████████| 86/86 [00:05<00:00, 14.74it/s, loss=0.659, accuracy=0.728, sensitivity=0.394, specificity=0.662]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training epoch [43/200], Training BCE loss:0.6041, Training accuracy:0.7886, Training sensitivity:0.7568, Training specificity:0.8348,                 Validation BCE loss:0.6586, Validation accuracy:0.7282, Validation sensitivity:0.3943, Validation specificity:0.6624,\n",
            "=> saved best model as validation loss is greater than previous best loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 246/246 [00:31<00:00,  7.74it/s, loss=0.602, accuracy=0.789, sensitivity=0.758, specificity=0.832]\n",
            "100%|██████████| 86/86 [00:05<00:00, 15.12it/s, loss=0.658, accuracy=0.728, sensitivity=0.386, specificity=0.669]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training epoch [44/200], Training BCE loss:0.6022, Training accuracy:0.7886, Training sensitivity:0.7577, Training specificity:0.8322,                 Validation BCE loss:0.6577, Validation accuracy:0.7277, Validation sensitivity:0.3860, Validation specificity:0.6686,\n",
            "=> saved best model as validation loss is greater than previous best loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 246/246 [00:31<00:00,  7.69it/s, loss=0.599, accuracy=0.801, sensitivity=0.768, specificity=0.841]\n",
            "100%|██████████| 86/86 [00:05<00:00, 14.79it/s, loss=0.658, accuracy=0.729, sensitivity=0.396, specificity=0.658]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training epoch [45/200], Training BCE loss:0.5991, Training accuracy:0.8006, Training sensitivity:0.7684, Training specificity:0.8407,                 Validation BCE loss:0.6578, Validation accuracy:0.7287, Validation sensitivity:0.3955, Validation specificity:0.6576,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 246/246 [00:31<00:00,  7.74it/s, loss=0.599, accuracy=0.8, sensitivity=0.772, specificity=0.842]\n",
            "100%|██████████| 86/86 [00:05<00:00, 14.95it/s, loss=0.657, accuracy=0.726, sensitivity=0.384, specificity=0.665]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training epoch [46/200], Training BCE loss:0.5995, Training accuracy:0.7996, Training sensitivity:0.7720, Training specificity:0.8421,                 Validation BCE loss:0.6568, Validation accuracy:0.7262, Validation sensitivity:0.3842, Validation specificity:0.6650,\n",
            "=> saved best model as validation loss is greater than previous best loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 246/246 [00:31<00:00,  7.69it/s, loss=0.598, accuracy=0.802, sensitivity=0.774, specificity=0.843]\n",
            "100%|██████████| 86/86 [00:05<00:00, 14.89it/s, loss=0.657, accuracy=0.728, sensitivity=0.389, specificity=0.661]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training epoch [47/200], Training BCE loss:0.5977, Training accuracy:0.8020, Training sensitivity:0.7739, Training specificity:0.8433,                 Validation BCE loss:0.6565, Validation accuracy:0.7282, Validation sensitivity:0.3892, Validation specificity:0.6612,\n",
            "=> saved best model as validation loss is greater than previous best loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 246/246 [00:31<00:00,  7.73it/s, loss=0.597, accuracy=0.8, sensitivity=0.764, specificity=0.847]\n",
            "100%|██████████| 86/86 [00:05<00:00, 14.86it/s, loss=0.656, accuracy=0.729, sensitivity=0.392, specificity=0.666]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training epoch [48/200], Training BCE loss:0.5969, Training accuracy:0.7996, Training sensitivity:0.7644, Training specificity:0.8468,                 Validation BCE loss:0.6556, Validation accuracy:0.7287, Validation sensitivity:0.3917, Validation specificity:0.6656,\n",
            "=> saved best model as validation loss is greater than previous best loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 246/246 [00:31<00:00,  7.71it/s, loss=0.594, accuracy=0.806, sensitivity=0.776, specificity=0.848]\n",
            "100%|██████████| 86/86 [00:05<00:00, 14.90it/s, loss=0.656, accuracy=0.729, sensitivity=0.395, specificity=0.66]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training epoch [49/200], Training BCE loss:0.5945, Training accuracy:0.8061, Training sensitivity:0.7758, Training specificity:0.8475,                 Validation BCE loss:0.6557, Validation accuracy:0.7287, Validation sensitivity:0.3953, Validation specificity:0.6600,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 246/246 [00:31<00:00,  7.72it/s, loss=0.592, accuracy=0.81, sensitivity=0.78, specificity=0.848]\n",
            "100%|██████████| 86/86 [00:05<00:00, 14.97it/s, loss=0.655, accuracy=0.729, sensitivity=0.392, specificity=0.662]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training epoch [50/200], Training BCE loss:0.5923, Training accuracy:0.8098, Training sensitivity:0.7805, Training specificity:0.8482,                 Validation BCE loss:0.6554, Validation accuracy:0.7292, Validation sensitivity:0.3918, Validation specificity:0.6623,\n",
            "=> saved best model as validation loss is greater than previous best loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 246/246 [00:31<00:00,  7.72it/s, loss=0.59, accuracy=0.819, sensitivity=0.783, specificity=0.861]\n",
            "100%|██████████| 86/86 [00:05<00:00, 14.73it/s, loss=0.655, accuracy=0.728, sensitivity=0.389, specificity=0.662]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training epoch [51/200], Training BCE loss:0.5899, Training accuracy:0.8186, Training sensitivity:0.7833, Training specificity:0.8614,                 Validation BCE loss:0.6550, Validation accuracy:0.7282, Validation sensitivity:0.3889, Validation specificity:0.6618,\n",
            "=> saved best model as validation loss is greater than previous best loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 246/246 [00:31<00:00,  7.74it/s, loss=0.59, accuracy=0.812, sensitivity=0.777, specificity=0.857]\n",
            "100%|██████████| 86/86 [00:05<00:00, 15.06it/s, loss=0.655, accuracy=0.729, sensitivity=0.392, specificity=0.662]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training epoch [52/200], Training BCE loss:0.5901, Training accuracy:0.8123, Training sensitivity:0.7773, Training specificity:0.8574,                 Validation BCE loss:0.6546, Validation accuracy:0.7287, Validation sensitivity:0.3920, Validation specificity:0.6623,\n",
            "=> saved best model as validation loss is greater than previous best loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 246/246 [00:31<00:00,  7.72it/s, loss=0.589, accuracy=0.816, sensitivity=0.781, specificity=0.863]\n",
            "100%|██████████| 86/86 [00:05<00:00, 15.18it/s, loss=0.654, accuracy=0.728, sensitivity=0.381, specificity=0.67]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training epoch [53/200], Training BCE loss:0.5889, Training accuracy:0.8159, Training sensitivity:0.7815, Training specificity:0.8632,                 Validation BCE loss:0.6539, Validation accuracy:0.7277, Validation sensitivity:0.3809, Validation specificity:0.6697,\n",
            "=> saved best model as validation loss is greater than previous best loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 246/246 [00:31<00:00,  7.71it/s, loss=0.588, accuracy=0.818, sensitivity=0.787, specificity=0.864]\n",
            "100%|██████████| 86/86 [00:05<00:00, 15.05it/s, loss=0.654, accuracy=0.727, sensitivity=0.39, specificity=0.661]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training epoch [54/200], Training BCE loss:0.5876, Training accuracy:0.8179, Training sensitivity:0.7875, Training specificity:0.8638,                 Validation BCE loss:0.6541, Validation accuracy:0.7272, Validation sensitivity:0.3902, Validation specificity:0.6607,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 246/246 [00:31<00:00,  7.72it/s, loss=0.585, accuracy=0.825, sensitivity=0.792, specificity=0.868]\n",
            "100%|██████████| 86/86 [00:05<00:00, 14.91it/s, loss=0.654, accuracy=0.726, sensitivity=0.396, specificity=0.658]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training epoch [55/200], Training BCE loss:0.5852, Training accuracy:0.8252, Training sensitivity:0.7923, Training specificity:0.8683,                 Validation BCE loss:0.6538, Validation accuracy:0.7258, Validation sensitivity:0.3962, Validation specificity:0.6584,\n",
            "=> saved best model as validation loss is greater than previous best loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 246/246 [00:31<00:00,  7.69it/s, loss=0.584, accuracy=0.825, sensitivity=0.788, specificity=0.874]\n",
            "100%|██████████| 86/86 [00:05<00:00, 14.98it/s, loss=0.653, accuracy=0.726, sensitivity=0.391, specificity=0.663]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training epoch [56/200], Training BCE loss:0.5844, Training accuracy:0.8254, Training sensitivity:0.7880, Training specificity:0.8738,                 Validation BCE loss:0.6532, Validation accuracy:0.7262, Validation sensitivity:0.3909, Validation specificity:0.6625,\n",
            "=> saved best model as validation loss is greater than previous best loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 246/246 [00:32<00:00,  7.65it/s, loss=0.583, accuracy=0.825, sensitivity=0.792, specificity=0.869]\n",
            "100%|██████████| 86/86 [00:05<00:00, 14.71it/s, loss=0.654, accuracy=0.722, sensitivity=0.393, specificity=0.652]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training epoch [57/200], Training BCE loss:0.5832, Training accuracy:0.8247, Training sensitivity:0.7918, Training specificity:0.8687,                 Validation BCE loss:0.6535, Validation accuracy:0.7223, Validation sensitivity:0.3930, Validation specificity:0.6521,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 246/246 [00:32<00:00,  7.67it/s, loss=0.582, accuracy=0.829, sensitivity=0.794, specificity=0.874]\n",
            "100%|██████████| 86/86 [00:05<00:00, 14.78it/s, loss=0.653, accuracy=0.722, sensitivity=0.385, specificity=0.658]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training epoch [58/200], Training BCE loss:0.5823, Training accuracy:0.8291, Training sensitivity:0.7938, Training specificity:0.8737,                 Validation BCE loss:0.6529, Validation accuracy:0.7218, Validation sensitivity:0.3855, Validation specificity:0.6579,\n",
            "=> saved best model as validation loss is greater than previous best loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 246/246 [00:32<00:00,  7.68it/s, loss=0.578, accuracy=0.838, sensitivity=0.803, specificity=0.881]\n",
            "100%|██████████| 86/86 [00:05<00:00, 14.72it/s, loss=0.653, accuracy=0.723, sensitivity=0.39, specificity=0.654]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training epoch [59/200], Training BCE loss:0.5784, Training accuracy:0.8377, Training sensitivity:0.8032, Training specificity:0.8813,                 Validation BCE loss:0.6529, Validation accuracy:0.7228, Validation sensitivity:0.3895, Validation specificity:0.6545,\n",
            "=> saved best model as validation loss is greater than previous best loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 246/246 [00:31<00:00,  7.73it/s, loss=0.579, accuracy=0.835, sensitivity=0.803, specificity=0.878]\n",
            "100%|██████████| 86/86 [00:05<00:00, 15.04it/s, loss=0.652, accuracy=0.722, sensitivity=0.385, specificity=0.658]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training epoch [60/200], Training BCE loss:0.5788, Training accuracy:0.8354, Training sensitivity:0.8035, Training specificity:0.8780,                 Validation BCE loss:0.6525, Validation accuracy:0.7218, Validation sensitivity:0.3852, Validation specificity:0.6578,\n",
            "=> saved best model as validation loss is greater than previous best loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 246/246 [00:31<00:00,  7.72it/s, loss=0.578, accuracy=0.84, sensitivity=0.807, specificity=0.882]\n",
            "100%|██████████| 86/86 [00:05<00:00, 14.96it/s, loss=0.652, accuracy=0.722, sensitivity=0.388, specificity=0.658]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training epoch [61/200], Training BCE loss:0.5779, Training accuracy:0.8396, Training sensitivity:0.8073, Training specificity:0.8824,                 Validation BCE loss:0.6522, Validation accuracy:0.7223, Validation sensitivity:0.3880, Validation specificity:0.6580,\n",
            "=> saved best model as validation loss is greater than previous best loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 246/246 [00:31<00:00,  7.74it/s, loss=0.576, accuracy=0.841, sensitivity=0.803, specificity=0.886]\n",
            "100%|██████████| 86/86 [00:05<00:00, 15.08it/s, loss=0.652, accuracy=0.721, sensitivity=0.385, specificity=0.66]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training epoch [62/200], Training BCE loss:0.5761, Training accuracy:0.8410, Training sensitivity:0.8031, Training specificity:0.8858,                 Validation BCE loss:0.6522, Validation accuracy:0.7209, Validation sensitivity:0.3847, Validation specificity:0.6599,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 246/246 [00:31<00:00,  7.74it/s, loss=0.574, accuracy=0.848, sensitivity=0.814, specificity=0.889]\n",
            "100%|██████████| 86/86 [00:05<00:00, 14.52it/s, loss=0.652, accuracy=0.723, sensitivity=0.386, specificity=0.66]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training epoch [63/200], Training BCE loss:0.5742, Training accuracy:0.8482, Training sensitivity:0.8142, Training specificity:0.8889,                 Validation BCE loss:0.6520, Validation accuracy:0.7228, Validation sensitivity:0.3863, Validation specificity:0.6604,\n",
            "=> saved best model as validation loss is greater than previous best loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 246/246 [00:32<00:00,  7.69it/s, loss=0.575, accuracy=0.841, sensitivity=0.807, specificity=0.887]\n",
            "100%|██████████| 86/86 [00:05<00:00, 14.81it/s, loss=0.652, accuracy=0.721, sensitivity=0.387, specificity=0.658]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training epoch [64/200], Training BCE loss:0.5753, Training accuracy:0.8408, Training sensitivity:0.8072, Training specificity:0.8870,                 Validation BCE loss:0.6521, Validation accuracy:0.7209, Validation sensitivity:0.3869, Validation specificity:0.6579,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 246/246 [00:31<00:00,  7.74it/s, loss=0.574, accuracy=0.846, sensitivity=0.812, specificity=0.89]\n",
            "100%|██████████| 86/86 [00:05<00:00, 14.95it/s, loss=0.652, accuracy=0.722, sensitivity=0.387, specificity=0.659]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training epoch [65/200], Training BCE loss:0.5737, Training accuracy:0.8455, Training sensitivity:0.8117, Training specificity:0.8900,                 Validation BCE loss:0.6522, Validation accuracy:0.7223, Validation sensitivity:0.3869, Validation specificity:0.6594,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 246/246 [00:31<00:00,  7.72it/s, loss=0.572, accuracy=0.846, sensitivity=0.806, specificity=0.896]\n",
            "100%|██████████| 86/86 [00:05<00:00, 14.80it/s, loss=0.652, accuracy=0.72, sensitivity=0.388, specificity=0.655]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training epoch [66/200], Training BCE loss:0.5716, Training accuracy:0.8464, Training sensitivity:0.8056, Training specificity:0.8963,                 Validation BCE loss:0.6524, Validation accuracy:0.7204, Validation sensitivity:0.3885, Validation specificity:0.6547,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 246/246 [00:31<00:00,  7.72it/s, loss=0.571, accuracy=0.852, sensitivity=0.812, specificity=0.902]\n",
            "100%|██████████| 86/86 [00:05<00:00, 14.97it/s, loss=0.652, accuracy=0.721, sensitivity=0.395, specificity=0.653]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training epoch [67/200], Training BCE loss:0.5709, Training accuracy:0.8518, Training sensitivity:0.8125, Training specificity:0.9015,                 Validation BCE loss:0.6523, Validation accuracy:0.7209, Validation sensitivity:0.3946, Validation specificity:0.6527,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 246/246 [00:31<00:00,  7.72it/s, loss=0.569, accuracy=0.853, sensitivity=0.814, specificity=0.9]\n",
            "100%|██████████| 86/86 [00:05<00:00, 14.78it/s, loss=0.652, accuracy=0.721, sensitivity=0.388, specificity=0.657]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training epoch [68/200], Training BCE loss:0.5689, Training accuracy:0.8533, Training sensitivity:0.8142, Training specificity:0.9001,                 Validation BCE loss:0.6519, Validation accuracy:0.7214, Validation sensitivity:0.3883, Validation specificity:0.6570,\n",
            "=> saved best model as validation loss is greater than previous best loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 246/246 [00:31<00:00,  7.73it/s, loss=0.567, accuracy=0.858, sensitivity=0.817, specificity=0.904]\n",
            "100%|██████████| 86/86 [00:05<00:00, 14.95it/s, loss=0.652, accuracy=0.722, sensitivity=0.396, specificity=0.652]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training epoch [69/200], Training BCE loss:0.5670, Training accuracy:0.8582, Training sensitivity:0.8174, Training specificity:0.9043,                 Validation BCE loss:0.6522, Validation accuracy:0.7223, Validation sensitivity:0.3965, Validation specificity:0.6515,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 246/246 [00:31<00:00,  7.70it/s, loss=0.566, accuracy=0.859, sensitivity=0.821, specificity=0.903]\n",
            "100%|██████████| 86/86 [00:05<00:00, 14.86it/s, loss=0.652, accuracy=0.722, sensitivity=0.392, specificity=0.654]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training epoch [70/200], Training BCE loss:0.5661, Training accuracy:0.8592, Training sensitivity:0.8213, Training specificity:0.9030,                 Validation BCE loss:0.6518, Validation accuracy:0.7218, Validation sensitivity:0.3916, Validation specificity:0.6537,\n",
            "=> saved best model as validation loss is greater than previous best loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 246/246 [00:31<00:00,  7.70it/s, loss=0.566, accuracy=0.861, sensitivity=0.826, specificity=0.906]\n",
            "100%|██████████| 86/86 [00:05<00:00, 14.67it/s, loss=0.652, accuracy=0.722, sensitivity=0.393, specificity=0.654]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training epoch [71/200], Training BCE loss:0.5658, Training accuracy:0.8609, Training sensitivity:0.8263, Training specificity:0.9057,                 Validation BCE loss:0.6517, Validation accuracy:0.7223, Validation sensitivity:0.3926, Validation specificity:0.6537,\n",
            "=> saved best model as validation loss is greater than previous best loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 246/246 [00:32<00:00,  7.67it/s, loss=0.566, accuracy=0.861, sensitivity=0.823, specificity=0.907]\n",
            "100%|██████████| 86/86 [00:05<00:00, 15.06it/s, loss=0.651, accuracy=0.722, sensitivity=0.388, specificity=0.655]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training epoch [72/200], Training BCE loss:0.5656, Training accuracy:0.8614, Training sensitivity:0.8234, Training specificity:0.9074,                 Validation BCE loss:0.6513, Validation accuracy:0.7218, Validation sensitivity:0.3879, Validation specificity:0.6554,\n",
            "=> saved best model as validation loss is greater than previous best loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 246/246 [00:31<00:00,  7.73it/s, loss=0.563, accuracy=0.865, sensitivity=0.83, specificity=0.909]\n",
            "100%|██████████| 86/86 [00:05<00:00, 14.63it/s, loss=0.652, accuracy=0.72, sensitivity=0.392, specificity=0.651]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training epoch [73/200], Training BCE loss:0.5632, Training accuracy:0.8647, Training sensitivity:0.8295, Training specificity:0.9086,                 Validation BCE loss:0.6516, Validation accuracy:0.7199, Validation sensitivity:0.3918, Validation specificity:0.6507,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 246/246 [00:32<00:00,  7.68it/s, loss=0.563, accuracy=0.867, sensitivity=0.833, specificity=0.911]\n",
            "100%|██████████| 86/86 [00:05<00:00, 14.66it/s, loss=0.652, accuracy=0.719, sensitivity=0.392, specificity=0.65]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training epoch [74/200], Training BCE loss:0.5629, Training accuracy:0.8670, Training sensitivity:0.8331, Training specificity:0.9107,                 Validation BCE loss:0.6518, Validation accuracy:0.7194, Validation sensitivity:0.3923, Validation specificity:0.6501,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 246/246 [00:31<00:00,  7.72it/s, loss=0.562, accuracy=0.867, sensitivity=0.834, specificity=0.906]\n",
            "100%|██████████| 86/86 [00:05<00:00, 14.54it/s, loss=0.652, accuracy=0.721, sensitivity=0.393, specificity=0.653]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training epoch [75/200], Training BCE loss:0.5622, Training accuracy:0.8669, Training sensitivity:0.8339, Training specificity:0.9060,                 Validation BCE loss:0.6518, Validation accuracy:0.7214, Validation sensitivity:0.3927, Validation specificity:0.6526,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 246/246 [00:31<00:00,  7.70it/s, loss=0.561, accuracy=0.869, sensitivity=0.834, specificity=0.912]\n",
            "100%|██████████| 86/86 [00:05<00:00, 14.85it/s, loss=0.652, accuracy=0.72, sensitivity=0.395, specificity=0.648]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training epoch [76/200], Training BCE loss:0.5608, Training accuracy:0.8692, Training sensitivity:0.8338, Training specificity:0.9115,                 Validation BCE loss:0.6519, Validation accuracy:0.7204, Validation sensitivity:0.3947, Validation specificity:0.6484,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 246/246 [00:31<00:00,  7.69it/s, loss=0.559, accuracy=0.87, sensitivity=0.833, specificity=0.914]\n",
            "100%|██████████| 86/86 [00:05<00:00, 14.81it/s, loss=0.652, accuracy=0.72, sensitivity=0.392, specificity=0.649]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training epoch [77/200], Training BCE loss:0.5589, Training accuracy:0.8699, Training sensitivity:0.8334, Training specificity:0.9139,                 Validation BCE loss:0.6517, Validation accuracy:0.7199, Validation sensitivity:0.3921, Validation specificity:0.6493,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 246/246 [00:32<00:00,  7.68it/s, loss=0.559, accuracy=0.87, sensitivity=0.831, specificity=0.914]\n",
            "100%|██████████| 86/86 [00:05<00:00, 14.72it/s, loss=0.651, accuracy=0.72, sensitivity=0.389, specificity=0.653]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training epoch [78/200], Training BCE loss:0.5590, Training accuracy:0.8699, Training sensitivity:0.8312, Training specificity:0.9136,                 Validation BCE loss:0.6514, Validation accuracy:0.7199, Validation sensitivity:0.3891, Validation specificity:0.6530,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 246/246 [00:32<00:00,  7.68it/s, loss=0.557, accuracy=0.875, sensitivity=0.844, specificity=0.913]\n",
            "100%|██████████| 86/86 [00:06<00:00, 14.31it/s, loss=0.652, accuracy=0.72, sensitivity=0.393, specificity=0.648]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training epoch [79/200], Training BCE loss:0.5565, Training accuracy:0.8753, Training sensitivity:0.8440, Training specificity:0.9133,                 Validation BCE loss:0.6518, Validation accuracy:0.7199, Validation sensitivity:0.3931, Validation specificity:0.6479,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 246/246 [00:32<00:00,  7.64it/s, loss=0.556, accuracy=0.878, sensitivity=0.843, specificity=0.917]\n",
            "100%|██████████| 86/86 [00:05<00:00, 14.69it/s, loss=0.652, accuracy=0.719, sensitivity=0.394, specificity=0.645]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training epoch [80/200], Training BCE loss:0.5563, Training accuracy:0.8782, Training sensitivity:0.8433, Training specificity:0.9168,                 Validation BCE loss:0.6519, Validation accuracy:0.7189, Validation sensitivity:0.3942, Validation specificity:0.6453,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 246/246 [00:31<00:00,  7.72it/s, loss=0.556, accuracy=0.88, sensitivity=0.849, specificity=0.917]\n",
            "100%|██████████| 86/86 [00:05<00:00, 14.80it/s, loss=0.652, accuracy=0.719, sensitivity=0.393, specificity=0.647]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training epoch [81/200], Training BCE loss:0.5560, Training accuracy:0.8803, Training sensitivity:0.8489, Training specificity:0.9167,                 Validation BCE loss:0.6522, Validation accuracy:0.7194, Validation sensitivity:0.3928, Validation specificity:0.6470,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 246/246 [00:31<00:00,  7.71it/s, loss=0.555, accuracy=0.884, sensitivity=0.854, specificity=0.92]\n",
            "100%|██████████| 86/86 [00:05<00:00, 14.87it/s, loss=0.652, accuracy=0.719, sensitivity=0.393, specificity=0.647]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training epoch [82/200], Training BCE loss:0.5552, Training accuracy:0.8838, Training sensitivity:0.8536, Training specificity:0.9197,                 Validation BCE loss:0.6522, Validation accuracy:0.7189, Validation sensitivity:0.3927, Validation specificity:0.6474,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 246/246 [00:31<00:00,  7.70it/s, loss=0.554, accuracy=0.884, sensitivity=0.845, specificity=0.929]\n",
            "100%|██████████| 86/86 [00:05<00:00, 14.64it/s, loss=0.652, accuracy=0.72, sensitivity=0.395, specificity=0.646]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training epoch [83/200], Training BCE loss:0.5542, Training accuracy:0.8843, Training sensitivity:0.8451, Training specificity:0.9285,                 Validation BCE loss:0.6523, Validation accuracy:0.7199, Validation sensitivity:0.3952, Validation specificity:0.6455,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 246/246 [00:31<00:00,  7.74it/s, loss=0.554, accuracy=0.879, sensitivity=0.844, specificity=0.92]\n",
            "100%|██████████| 86/86 [00:05<00:00, 14.88it/s, loss=0.653, accuracy=0.719, sensitivity=0.396, specificity=0.642]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training epoch [84/200], Training BCE loss:0.5540, Training accuracy:0.8792, Training sensitivity:0.8439, Training specificity:0.9202,                 Validation BCE loss:0.6526, Validation accuracy:0.7189, Validation sensitivity:0.3957, Validation specificity:0.6425,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 246/246 [00:31<00:00,  7.71it/s, loss=0.554, accuracy=0.883, sensitivity=0.85, specificity=0.926]\n",
            "100%|██████████| 86/86 [00:05<00:00, 14.77it/s, loss=0.652, accuracy=0.717, sensitivity=0.392, specificity=0.646]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training epoch [85/200], Training BCE loss:0.5542, Training accuracy:0.8830, Training sensitivity:0.8496, Training specificity:0.9256,                 Validation BCE loss:0.6520, Validation accuracy:0.7174, Validation sensitivity:0.3915, Validation specificity:0.6461,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 246/246 [00:31<00:00,  7.71it/s, loss=0.551, accuracy=0.889, sensitivity=0.854, specificity=0.928]\n",
            "100%|██████████| 86/86 [00:05<00:00, 14.79it/s, loss=0.653, accuracy=0.716, sensitivity=0.399, specificity=0.639]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training epoch [86/200], Training BCE loss:0.5507, Training accuracy:0.8886, Training sensitivity:0.8539, Training specificity:0.9278,                 Validation BCE loss:0.6530, Validation accuracy:0.7165, Validation sensitivity:0.3994, Validation specificity:0.6392,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 246/246 [00:31<00:00,  7.71it/s, loss=0.55, accuracy=0.889, sensitivity=0.857, specificity=0.926]\n",
            "100%|██████████| 86/86 [00:05<00:00, 14.74it/s, loss=0.653, accuracy=0.716, sensitivity=0.396, specificity=0.64]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training epoch [87/200], Training BCE loss:0.5503, Training accuracy:0.8894, Training sensitivity:0.8570, Training specificity:0.9255,                 Validation BCE loss:0.6528, Validation accuracy:0.7165, Validation sensitivity:0.3960, Validation specificity:0.6397,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 246/246 [00:32<00:00,  7.64it/s, loss=0.551, accuracy=0.891, sensitivity=0.863, specificity=0.926]\n",
            "100%|██████████| 86/86 [00:05<00:00, 14.82it/s, loss=0.652, accuracy=0.718, sensitivity=0.4, specificity=0.643]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training epoch [88/200], Training BCE loss:0.5506, Training accuracy:0.8908, Training sensitivity:0.8626, Training specificity:0.9255,                 Validation BCE loss:0.6522, Validation accuracy:0.7184, Validation sensitivity:0.3995, Validation specificity:0.6435,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 246/246 [00:31<00:00,  7.71it/s, loss=0.551, accuracy=0.888, sensitivity=0.856, specificity=0.926]\n",
            "100%|██████████| 86/86 [00:05<00:00, 14.59it/s, loss=0.653, accuracy=0.716, sensitivity=0.403, specificity=0.635]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training epoch [89/200], Training BCE loss:0.5507, Training accuracy:0.8877, Training sensitivity:0.8563, Training specificity:0.9259,                 Validation BCE loss:0.6533, Validation accuracy:0.7165, Validation sensitivity:0.4033, Validation specificity:0.6354,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 246/246 [00:31<00:00,  7.71it/s, loss=0.548, accuracy=0.892, sensitivity=0.865, specificity=0.922]\n",
            "100%|██████████| 86/86 [00:05<00:00, 14.86it/s, loss=0.653, accuracy=0.716, sensitivity=0.401, specificity=0.637]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training epoch [90/200], Training BCE loss:0.5484, Training accuracy:0.8924, Training sensitivity:0.8649, Training specificity:0.9224,                 Validation BCE loss:0.6532, Validation accuracy:0.7165, Validation sensitivity:0.4014, Validation specificity:0.6372,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 246/246 [00:31<00:00,  7.69it/s, loss=0.549, accuracy=0.892, sensitivity=0.862, specificity=0.928]\n",
            "100%|██████████| 86/86 [00:05<00:00, 14.66it/s, loss=0.654, accuracy=0.715, sensitivity=0.404, specificity=0.633]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training epoch [91/200], Training BCE loss:0.5491, Training accuracy:0.8921, Training sensitivity:0.8619, Training specificity:0.9277,                 Validation BCE loss:0.6538, Validation accuracy:0.7150, Validation sensitivity:0.4038, Validation specificity:0.6332,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 246/246 [00:32<00:00,  7.67it/s, loss=0.546, accuracy=0.897, sensitivity=0.864, specificity=0.933]\n",
            "100%|██████████| 86/86 [00:05<00:00, 14.61it/s, loss=0.653, accuracy=0.715, sensitivity=0.397, specificity=0.638]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training epoch [92/200], Training BCE loss:0.5464, Training accuracy:0.8972, Training sensitivity:0.8643, Training specificity:0.9325,                 Validation BCE loss:0.6531, Validation accuracy:0.7150, Validation sensitivity:0.3971, Validation specificity:0.6384,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 246/246 [00:32<00:00,  7.64it/s, loss=0.548, accuracy=0.894, sensitivity=0.867, specificity=0.926]\n",
            "100%|██████████| 86/86 [00:05<00:00, 14.53it/s, loss=0.654, accuracy=0.714, sensitivity=0.398, specificity=0.635]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training epoch [93/200], Training BCE loss:0.5483, Training accuracy:0.8936, Training sensitivity:0.8667, Training specificity:0.9265,                 Validation BCE loss:0.6536, Validation accuracy:0.7135, Validation sensitivity:0.3982, Validation specificity:0.6349,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 246/246 [00:32<00:00,  7.64it/s, loss=0.547, accuracy=0.894, sensitivity=0.866, specificity=0.929]\n",
            "100%|██████████| 86/86 [00:05<00:00, 14.75it/s, loss=0.654, accuracy=0.715, sensitivity=0.4, specificity=0.635]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training epoch [94/200], Training BCE loss:0.5473, Training accuracy:0.8938, Training sensitivity:0.8662, Training specificity:0.9287,                 Validation BCE loss:0.6536, Validation accuracy:0.7150, Validation sensitivity:0.3996, Validation specificity:0.6353,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 246/246 [00:31<00:00,  7.69it/s, loss=0.544, accuracy=0.903, sensitivity=0.874, specificity=0.937]\n",
            "100%|██████████| 86/86 [00:05<00:00, 14.64it/s, loss=0.654, accuracy=0.714, sensitivity=0.399, specificity=0.635]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training epoch [95/200], Training BCE loss:0.5444, Training accuracy:0.9033, Training sensitivity:0.8743, Training specificity:0.9367,                 Validation BCE loss:0.6538, Validation accuracy:0.7135, Validation sensitivity:0.3986, Validation specificity:0.6348,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 246/246 [00:32<00:00,  7.67it/s, loss=0.545, accuracy=0.899, sensitivity=0.868, specificity=0.931]\n",
            "100%|██████████| 86/86 [00:05<00:00, 14.68it/s, loss=0.654, accuracy=0.714, sensitivity=0.401, specificity=0.634]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training epoch [96/200], Training BCE loss:0.5446, Training accuracy:0.8992, Training sensitivity:0.8680, Training specificity:0.9308,                 Validation BCE loss:0.6539, Validation accuracy:0.7135, Validation sensitivity:0.4005, Validation specificity:0.6340,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 246/246 [00:31<00:00,  7.71it/s, loss=0.545, accuracy=0.899, sensitivity=0.867, specificity=0.936]\n",
            "100%|██████████| 86/86 [00:05<00:00, 14.78it/s, loss=0.654, accuracy=0.712, sensitivity=0.406, specificity=0.628]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training epoch [97/200], Training BCE loss:0.5448, Training accuracy:0.8994, Training sensitivity:0.8669, Training specificity:0.9362,                 Validation BCE loss:0.6544, Validation accuracy:0.7120, Validation sensitivity:0.4060, Validation specificity:0.6283,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 246/246 [00:31<00:00,  7.69it/s, loss=0.543, accuracy=0.903, sensitivity=0.875, specificity=0.935]\n",
            "100%|██████████| 86/86 [00:05<00:00, 14.60it/s, loss=0.655, accuracy=0.714, sensitivity=0.409, specificity=0.63]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training epoch [98/200], Training BCE loss:0.5425, Training accuracy:0.9031, Training sensitivity:0.8753, Training specificity:0.9350,                 Validation BCE loss:0.6547, Validation accuracy:0.7140, Validation sensitivity:0.4086, Validation specificity:0.6297,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 246/246 [00:31<00:00,  7.69it/s, loss=0.543, accuracy=0.904, sensitivity=0.878, specificity=0.935]\n",
            "100%|██████████| 86/86 [00:05<00:00, 14.82it/s, loss=0.655, accuracy=0.714, sensitivity=0.408, specificity=0.63]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training epoch [99/200], Training BCE loss:0.5434, Training accuracy:0.9040, Training sensitivity:0.8783, Training specificity:0.9346,                 Validation BCE loss:0.6549, Validation accuracy:0.7135, Validation sensitivity:0.4081, Validation specificity:0.6297,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 246/246 [00:32<00:00,  7.60it/s, loss=0.542, accuracy=0.907, sensitivity=0.877, specificity=0.939]\n",
            "100%|██████████| 86/86 [00:05<00:00, 14.43it/s, loss=0.655, accuracy=0.714, sensitivity=0.405, specificity=0.632]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training epoch [100/200], Training BCE loss:0.5419, Training accuracy:0.9068, Training sensitivity:0.8768, Training specificity:0.9393,                 Validation BCE loss:0.6545, Validation accuracy:0.7135, Validation sensitivity:0.4050, Validation specificity:0.6319,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 246/246 [00:32<00:00,  7.61it/s, loss=0.541, accuracy=0.904, sensitivity=0.878, specificity=0.934]\n",
            "100%|██████████| 86/86 [00:06<00:00, 13.96it/s, loss=0.656, accuracy=0.714, sensitivity=0.409, specificity=0.628]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training epoch [101/200], Training BCE loss:0.5413, Training accuracy:0.9045, Training sensitivity:0.8785, Training specificity:0.9342,                 Validation BCE loss:0.6560, Validation accuracy:0.7140, Validation sensitivity:0.4091, Validation specificity:0.6281,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 246/246 [00:32<00:00,  7.56it/s, loss=0.541, accuracy=0.907, sensitivity=0.88, specificity=0.939]\n",
            "100%|██████████| 86/86 [00:05<00:00, 14.59it/s, loss=0.655, accuracy=0.714, sensitivity=0.402, specificity=0.633]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training epoch [102/200], Training BCE loss:0.5407, Training accuracy:0.9072, Training sensitivity:0.8795, Training specificity:0.9389,                 Validation BCE loss:0.6550, Validation accuracy:0.7135, Validation sensitivity:0.4021, Validation specificity:0.6329,\n",
            "=> early stopping\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **EVALUATE THE EFFICIENT NET MODEL**"
      ],
      "metadata": {
        "id": "Gg2bbD9AkfnH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(model,test_loader):\n",
        "    with torch.no_grad():\n",
        "        counter = 0\n",
        "        pbar = tqdm(total=len(test_loader))\n",
        "        TP,TN,FN,FP = 0,0,0,0\n",
        "        for images, labels in test_loader:\n",
        "            images = images.cuda()\n",
        "            labels = labels.cuda()\n",
        "\n",
        "            output = model(images)\n",
        "            outputs = output.view(-1)\n",
        "            labels = labels.type_as(outputs)\n",
        "            TP_batch,TN_batch,FN_batch,FP_batch = Confusion_matrix2(outputs,labels)\n",
        "            TP += TP_batch\n",
        "            TN += TN_batch\n",
        "            FN += FN_batch\n",
        "            FP += FP_batch\n",
        "            \n",
        "            pbar.update(1)\n",
        "        pbar.close()\n",
        "\n",
        "        accuracy = (TP+TN)/ (TP +TN +FN +FP)\n",
        "        sensitivity = TP / (TP+FN)\n",
        "        specificity = TN / (TN+FP)\n",
        "        precision = TP / (TP+FP)\n",
        "        F1 = (2*sensitivity*precision)/(precision+sensitivity)\n",
        "    torch.cuda.empty_cache()\n",
        "    return accuracy, sensitivity, specificity, precision,F1, TP,TN,FN,FP"
      ],
      "metadata": {
        "id": "QIMfF_g-WCgi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "filename = 0\n",
        "epochs = 200\n",
        "batch_size = 24\n",
        "early_stopping = 30\n",
        "num_workers = 2\n",
        "optimizer = 'Adam'\n",
        "learning_rate = 1e-6\n",
        "momentum = 0.9\n",
        "weight_decay = 1e-4\n",
        "\n",
        "OUTPUT_DIR = '/content/drive/MyDrive/data/Classification/model_output/efficientnetb0/'\n",
        "TEST_DIR = '/content/drive/MyDrive/data/Efficient_net/test/'\n",
        "CLEAN_TEST_DIR = '/content/drive/MyDrive/data/Efficient_net/clean_test/'\n",
        "LABEL_DIR ='/content/drive/MyDrive/data/Efficient_net/label/'\n",
        "\n",
        "with open(LABEL_DIR+'test.txt','rb') as fp:\n",
        "    test_label = pickle.load(fp)\n",
        "with open(LABEL_DIR+'clean_test.txt','rb') as fp:\n",
        "    clean_test_label = pickle.load(fp)\n",
        "\n",
        "print('-'*20)\n",
        "\n",
        "cudnn.benchmark = True\n",
        "model = EfficientNet.from_pretrained('efficientnet-b{}'.format(filename))\n",
        "\n",
        "#Fine tuning top layers\n",
        "num_ftrs = model._fc.in_features\n",
        "model._fc = nn.Sequential(nn.Linear(num_ftrs,1),\n",
        "                            nn.Sigmoid())\n",
        "\n",
        "if torch.cuda.device_count() > 1:\n",
        "    print(\"Let's use\", torch.cuda.device_count(), \"GPUs!\")\n",
        "    model = nn.DataParallel(model)\n",
        "\n",
        "model.load_state_dict(torch.load(OUTPUT_DIR +'model.pth'))\n",
        "model = model.cuda()\n",
        "\n",
        "# Get image files\n",
        "test_image_paths = load_directories(TEST_DIR)\n",
        "clean_test_image_paths = load_directories(CLEAN_TEST_DIR)\n",
        "\n",
        "test_image_paths.extend(clean_test_image_paths)\n",
        "test_label.extend(clean_test_label)\n",
        "\n",
        "assert len(test_image_paths)==len(test_label), \"Length of test images and test label not same\"\n",
        "print(\"============================TESTING===========================================\")\n",
        "print(\"Cancer nodules:{} Non Cancer nodules:{}\".format(np.sum(test_label),len(test_label)-np.sum(test_label)))\n",
        "print(\"Ratio is {:4f}\".format(np.sum(test_label)/(len(test_label)-np.sum(test_label))))\n",
        "\n",
        "test_dataset = ClassifierDataset(test_image_paths,test_label,Albumentation=False)\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(\n",
        "    test_dataset,\n",
        "    batch_size=batch_size,\n",
        "    shuffle=False,\n",
        "    pin_memory=True,\n",
        "    drop_last=False,\n",
        "    num_workers=6)\n",
        "\n",
        "log= pd.DataFrame(index=[],columns= ['test_size','accuracy','sensitivity','specificity','TP','TN','FN','FP'])\n",
        "\n",
        "accuracy, sensitivity, specificity, precision,F1, TP,TN,FN,FP = evaluate(model,test_loader)\n",
        "\n",
        "tmp = pd.Series([\n",
        "    len(test_dataset),accuracy, sensitivity, specificity, TP, TN, FN, FP\n",
        "], index=['test_size','accuracy','sensitivity','specificity','TP','TN','FN','FP'])\n",
        "\n",
        "print('Test accuracy:{:.4f}, Test sensitivity:{:.4f}, Testspecificity:{:.4f}'.format(accuracy,sensitivity,specificity))\n",
        "print('Test precision:{:.4f}, Test F1:{:.4f}'.format(precision,F1))\n",
        "log = log.append(tmp,ignore_index=True)\n",
        "log.to_csv(OUTPUT_DIR +'test_result.csv',index=False)\n",
        "print(\"OUTPUT RESULT SAVED AS CSV in\", OUTPUT_DIR)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zTuEeA8YRU1A",
        "outputId": "ed569cbc-7cae-4ee0-b810-ebaf621fe902"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------------------\n",
            "Loaded pretrained weights for efficientnet-b0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================TESTING===========================================\n",
            "Cancer nodules:1189 Non Cancer nodules:972\n",
            "Ratio is 1.223251\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 91/91 [02:11<00:00,  1.44s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test accuracy:0.5747, Test sensitivity:0.4853, Testspecificity:0.6842\n",
            "Test precision:0.6527, Test F1:0.5567\n",
            "OUTPUT RESULT SAVED AS CSV in /content/drive/MyDrive/data/Classification/model_output/efficientnetb0/\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "NMJDt95wRTlq"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}